{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"XYYLfyeDu3d1","executionInfo":{"status":"ok","timestamp":1693202530246,"user_tz":-540,"elapsed":4,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":410},"id":"OkkE2Xamu3d3","executionInfo":{"status":"error","timestamp":1693202540365,"user_tz":-540,"elapsed":6199,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"9ea6a0ef-0019-4917-8382-37173195c0a2"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-fdb018376eae>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import sys, os, time\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import pickle\n","import torch\n","import random\n","import utils\n","\n","import data_handler\n","from sklearn.utils import shuffle\n","import trainer\n","import networks\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eg9FAwcJu3d4"},"outputs":[],"source":["args = {}\n","\n","# general experimental setting\n","args['date'] = '230828'\n","args['dataset'] = 'MNIST'\n","args['trainer'] = 'ewc' # ER or EWC\n","args['seed'] = 0\n","args['output_path'] = '' # this is corrected at the next cell\n","\n","# setting for continual learning\n","args['tasknum'] = 5\n","\n","#hyperparameter for optimization\n","args['batch_size'] = 256\n","args['lr'] = 0.001\n","args['epochs'] = 10\n","args['decay'] = 0 # weight decay (L2 penaly for general regularization)\n","\n","args['schedule_milestone'] = [7] #Decrease learning rate at these epochs\n","args['gamma'] = 0.2\n","\n","\n","#hyperparameter for EWC\n","args['lamb'] = 1\n","\n","# for GPU, if you cannot use GPU, set device as None\n","device = 0\n","if device is not None:\n","    torch.cuda.set_device(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOLXsf4Su3d4"},"outputs":[],"source":["# Make directory for saving datasets, output files and trained models.\n","if not os.path.isdir('dat'):\n","    print('Make directory for dataset')\n","    os.makedirs('dat')\n","\n","if not os.path.isdir('result_data'):\n","    print('Make directory for saving results')\n","    os.makedirs('result_data')\n","\n","if not os.path.isdir('trained_model'):\n","    print('Make directory for saving trained models')\n","    os.makedirs('trained_model')\n","\n","# Make filename of a file for logging a result\n","log_name = '{}_{}_{}_{}_lamb_{}_lr_{}_batch_{}_epoch_{}'.format(args['date'], args['dataset'], args['trainer'],args['seed'],\n","                                                                       args['lamb'], args['lr'], args['batch_size'], args['epochs'])\n","\n","if args['output_path'] == '':\n","    args['output_path'] = './result_data/' + log_name + '.txt'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kRtC2mwHu3d5"},"outputs":[],"source":["# Fix seed for deterministic results\n","np.random.seed(args['seed'])\n","random.seed(args['seed'])\n","torch.manual_seed(args['seed'])\n","torch.backends.cudnn.deterministic = True\n","# device = torch.device(\"gpu\")\n","# torch.backends.cudnn.benchmark = False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C00M6gz1u3d5"},"outputs":[],"source":["#Load a dataset and a dataloader that outputs a task sequentially\n","print('Load data...')\n","data_dict = None\n","dataset = data_handler.DatasetFactory.get_dataset(args['dataset'], args['tasknum'])\n","task_info = dataset.task_info\n","print('\\nTask info =', task_info)\n","\n","# Loader used for training data\n","shuffle_idx = shuffle(np.arange(dataset.classes), random_state=args['seed'])\n","\n","# list of dataloaders: it consists of dataloaders for each task\n","train_dataset_loaders = data_handler.make_ContinualLoaders(dataset.train_data,\n","                                                        dataset.train_labels,\n","                                                        task_info,\n","                                                        transform=dataset.train_transform,\n","                                                        shuffle_idx = shuffle_idx,\n","                                                        data_dict = data_dict,\n","                                                       )\n","\n","test_dataset_loaders = data_handler.make_ContinualLoaders(dataset.test_data,\n","                                                       dataset.test_labels,\n","                                                       task_info,\n","                                                       transform=dataset.test_transform,\n","                                                       shuffle_idx = shuffle_idx,\n","                                                       data_dict = data_dict,\n","                                                      )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2T-OyJfqu3d6"},"outputs":[],"source":["# Get the required model\n","if device is not None:\n","    myModel = networks.ModelFactory.get_model(args['dataset'], args['trainer'], task_info).to(device)\n","else:\n","    myModel = networks.ModelFactory.get_model(args['dataset'], args['trainer'], task_info)\n","\n","# Define the optimizer used in the experiment\n","optimizer = torch.optim.Adam(myModel.parameters(), lr=args['lr'], weight_decay=args['decay'])\n","\n","# Initilize the evaluators used to measure the performance of the system.\n","t_classifier = trainer.EvaluatorFactory.get_evaluator(\"trainedClassifier\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0P9EFZ27u3d6"},"outputs":[],"source":["class Trainer(trainer.GenericTrainer):\n","    def __init__(self, model, args, optimizer, evaluator, task_info):\n","        super().__init__(model, args, optimizer, evaluator, task_info)\n","\n","        self.lamb=args['lamb']\n","\n","\n","    def train(self, train_loader, test_loader, t, device = None):\n","\n","        self.device = device\n","        self.setup_training(self.lr)\n","        # Do not update self.t\n","        if t>0: # update fisher before starting training new task\n","            self.update_frozen_model()\n","            self.update_fisher(device)\n","\n","        # Now, you can update self.t\n","        self.t = t\n","\n","        self.train_iterator = torch.utils.data.DataLoader(train_loader, batch_size=self.batch_size, shuffle=True)\n","        self.test_iterator = torch.utils.data.DataLoader(test_loader, 100, shuffle=False)\n","        self.fisher_iterator = torch.utils.data.DataLoader(train_loader, batch_size=20, shuffle=True)\n","\n","        for epoch in range(self.epochs):\n","            self.model.train()\n","            for samples in self.train_iterator:\n","                data, target = samples\n","                if device is not None:\n","                    data, target = data.to(device), target.to(device)\n","\n","                output = self.model(data)[t]\n","                loss_CE = self.criterion(output,target)\n","\n","                self.optimizer.zero_grad()\n","                (loss_CE).backward()\n","                self.optimizer.step()\n","            self.scheduler.step()\n","\n","            train_loss,train_acc = self.evaluator.evaluate(self.model, self.train_iterator, t, self.device)\n","            num_batch = len(self.train_iterator)\n","            print('| Epoch {:3d} | Train: loss={:.3f}, acc={:5.1f}% |'.format(epoch+1,train_loss,100*train_acc),end='')\n","            test_loss,test_acc=self.evaluator.evaluate(self.model, self.test_iterator, t, self.device)\n","            print(' Test: loss={:.3f}, acc={:5.1f}% |'.format(test_loss,100*test_acc),end='')\n","            print()\n","\n","    def criterion(self,output,targets):\n","        \"\"\"\n","        Arguments: output (The output logit of self.model), targets (Ground truth label)\n","        Return: loss function for the regularization-based continual learning\n","\n","        For the hyperparameter on regularization, please use self.lamb\n","        \"\"\"\n","        #######################################################################################\n","        # Write youre code here\n","        #######################################################################################\n","\n","    def compute_diag_fisher(self, device=None):\n","        \"\"\"\n","        Arguments: None. Just use global variables (self.model, self.criterion, ...)\n","        Return: Diagonal Fisher matrix.\n","\n","        This function will be used in the function 'update_fisher'\n","        \"\"\"\n","        #######################################################################################\n","        # Write youre code here\n","        #######################################################################################\n","\n","    def update_fisher(self, device):\n","\n","        \"\"\"\n","        Arguments: None. Just use global variables (self.model, self.fisher, ...)\n","        Return: None. Just update the global variable self.fisher\n","        Use 'compute_diag_fisher' to compute the fisher matrix\n","\n","        hint : pytorch function\n","        pseudo code\n","        \"\"\"\n","        #######################################################################################\n","        #  Write youre code here\n","        #######################################################################################\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cy4h07oYu3d7"},"outputs":[],"source":["# Trainer object used for training\n","myTrainer = Trainer(myModel, args, optimizer, t_classifier, task_info)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"udAPnmTxu3d7"},"outputs":[],"source":["########################################################################################################################\n","\n","utils.print_model_report(myModel)\n","utils.print_optimizer_config(optimizer)\n","print('-' * 100)\n","\n","# Loop tasks\n","acc = np.zeros((len(task_info), len(task_info)), dtype=np.float32)\n","lss = np.zeros((len(task_info), len(task_info)), dtype=np.float32)\n","for t, ncla in task_info:\n","    print(\"tasknum:\", t)\n","    # Add new classes to the train, and test iterator\n","\n","    train_loader = train_dataset_loaders[t]\n","    test_loader = test_dataset_loaders[t]\n","    print(device)\n","    myTrainer.train(train_loader, test_loader, t, device)\n","\n","    for u in range(t+1):\n","        test_loader = test_dataset_loaders[u]\n","        test_iterator = torch.utils.data.DataLoader(test_loader, 100, shuffle=False)\n","        test_loss, test_acc = t_classifier.evaluate(myTrainer.model, test_iterator, u, device)\n","        print('>>> Test on task {:2d}: loss={:.3f}, acc={:5.1f}% <<<'.format(u, test_loss, 100 * test_acc))\n","        acc[t, u] = test_acc\n","        lss[t, u] = test_loss\n","\n","    print('Average accuracy={:5.1f}%'.format(100 * np.mean(acc[t,:t+1])))\n","\n","    print('Save at ' + args['output_path'])\n","    np.savetxt(args['output_path'], acc, '%.4f')\n","    torch.save(myModel.state_dict(), './trained_model/' + log_name + '_task_{}.pt'.format(t))\n","\n","\n","print('*' * 100)\n","print('Accuracies =')\n","for i in range(acc.shape[0]):\n","    print('\\t', end='')\n","    for j in range(acc.shape[1]):\n","        print('{:5.1f}% '.format(100 * acc[i, j]), end='')\n","    print()\n","print('*' * 100)\n","print('Done!')\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-RLk2ELu3d7"},"outputs":[],"source":["def avg_acc(file_name):\n","    acc_arr = np.loadtxt(file_name)\n","    avg_acc_arr = np.zeros(acc_arr.shape[1])\n","    for i in range(acc_arr.shape[1]):\n","        avg_acc_arr[i] = np.mean(acc_arr[i][:i+1])\n","\n","    return avg_acc_arr\n","filename = ''\n","results = avg_acc(filename)\n","print(results)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPe0jnv7u3d7"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","task_num = args['tasknum']\n","task = np.arange(task_num) +1\n","ax = plt.subplot(111)\n","\n","# for key in results.keys():\n","ax.plot(task, results, label = 'ewc', linestyle = '-', marker = '.')\n","\n","box = ax.get_position()\n","ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n","plt.xticks(task)\n","\n","plt.xlabel('Task',fontsize = 20)\n","plt.ylabel('Accuracy',fontsize = 20)\n","\n","ax.legend(loc = 'center right', bbox_to_anchor=(1.3, 0.5))\n","plt.show()\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIP4e5qGu3d8"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}