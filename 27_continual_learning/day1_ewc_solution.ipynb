{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "import utils\n",
    "\n",
    "import data_handler\n",
    "from sklearn.utils import shuffle\n",
    "import trainer\n",
    "import networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "# general experimental setting \n",
    "args['date'] = '210806'\n",
    "args['dataset'] = 'MNIST'\n",
    "args['trainer'] = 'ewc' # ER or EWC\n",
    "args['seed'] = 0\n",
    "args['output_path'] = '' # this is corrected at the next cell\n",
    "\n",
    "# setting for continual learning \n",
    "args['tasknum'] = 5\n",
    "\n",
    "#hyperparameter for optimization\n",
    "args['batch_size'] = 256\n",
    "args['lr'] = 0.001\n",
    "args['epochs'] = 10\n",
    "args['decay'] = 0 # weight decay (L2 penaly for general regularization)\n",
    "\n",
    "args['schedule_milestone'] = [7] #Decrease learning rate at these epochs\n",
    "args['gamma'] = 0.2\n",
    "\n",
    "\n",
    "#hyperparameter for EWC\n",
    "args['lamb'] = 1\n",
    "\n",
    "# for GPU, if you cannot use GPU, set device as None\n",
    "device = 0\n",
    "if device is not None:\n",
    "    torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory for saving datasets, output files and trained models.\n",
    "if not os.path.isdir('dat'):\n",
    "    print('Make directory for dataset')\n",
    "    os.makedirs('dat')\n",
    "\n",
    "if not os.path.isdir('result_data'):\n",
    "    print('Make directory for saving results')\n",
    "    os.makedirs('result_data')\n",
    "\n",
    "if not os.path.isdir('trained_model'):\n",
    "    print('Make directory for saving trained models')\n",
    "    os.makedirs('trained_model')\n",
    "\n",
    "# Make filename of a file for logging a result\n",
    "log_name = '{}_{}_{}_{}_lamb_{}_lr_{}_batch_{}_epoch_{}'.format(args['date'], args['dataset'], args['trainer'],args['seed'], \n",
    "                                                                       args['lamb'], args['lr'], args['batch_size'], args['epochs'])\n",
    "\n",
    "if args['output_path'] == '':\n",
    "    args['output_path'] = './result_data/' + log_name + '.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seed for deterministic results\n",
    "np.random.seed(args['seed'])\n",
    "random.seed(args['seed'])\n",
    "torch.manual_seed(args['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# device = torch.device(\"gpu\")\n",
    "# torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a dataset and a dataloader that outputs a task sequentially\n",
    "print('Load data...')\n",
    "data_dict = None\n",
    "dataset = data_handler.DatasetFactory.get_dataset(args['dataset'], args['tasknum'])\n",
    "task_info = dataset.task_info\n",
    "print('\\nTask info =', task_info)\n",
    "\n",
    "# Loader used for training data\n",
    "shuffle_idx = shuffle(np.arange(dataset.classes), random_state=args['seed'])\n",
    "\n",
    "# list of dataloaders: it consists of dataloaders for each task\n",
    "train_dataset_loaders = data_handler.make_ContinualLoaders(dataset.train_data,\n",
    "                                                        dataset.train_labels,\n",
    "                                                        task_info,\n",
    "                                                        transform=dataset.train_transform,\n",
    "                                                        shuffle_idx = shuffle_idx,\n",
    "                                                        data_dict = data_dict,\n",
    "                                                       )\n",
    "\n",
    "test_dataset_loaders = data_handler.make_ContinualLoaders(dataset.test_data,\n",
    "                                                       dataset.test_labels,\n",
    "                                                       task_info,\n",
    "                                                       transform=dataset.test_transform,\n",
    "                                                       shuffle_idx = shuffle_idx,\n",
    "                                                       data_dict = data_dict,\n",
    "                                                      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the required model\n",
    "if device is not None:\n",
    "    myModel = networks.ModelFactory.get_model(args['dataset'], args['trainer'], task_info).to(device)\n",
    "else:\n",
    "    myModel = networks.ModelFactory.get_model(args['dataset'], args['trainer'], task_info)\n",
    "\n",
    "# Define the optimizer used in the experiment\n",
    "optimizer = torch.optim.Adam(myModel.parameters(), lr=args['lr'], weight_decay=args['decay'])\n",
    "\n",
    "# Initilize the evaluators used to measure the performance of the system.\n",
    "t_classifier = trainer.EvaluatorFactory.get_evaluator(\"trainedClassifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(trainer.GenericTrainer):\n",
    "    def __init__(self, model, args, optimizer, evaluator, task_info):\n",
    "        super().__init__(model, args, optimizer, evaluator, task_info)\n",
    "        \n",
    "        self.lamb=args['lamb']\n",
    "        \n",
    "\n",
    "    def train(self, train_loader, test_loader, t, device = None):\n",
    "        \n",
    "        self.device = device\n",
    "        self.setup_training(self.lr)\n",
    "        # Do not update self.t\n",
    "        if t>0: # update fisher before starting training new task\n",
    "            self.update_frozen_model()\n",
    "            self.update_fisher(device)\n",
    "        \n",
    "        # Now, you can update self.t\n",
    "        self.t = t\n",
    "        \n",
    "        self.train_iterator = torch.utils.data.DataLoader(train_loader, batch_size=self.batch_size, shuffle=True)\n",
    "        self.test_iterator = torch.utils.data.DataLoader(test_loader, 100, shuffle=False)\n",
    "        self.fisher_iterator = torch.utils.data.DataLoader(train_loader, batch_size=20, shuffle=True)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            for samples in self.train_iterator:\n",
    "                data, target = samples\n",
    "                if device is not None:\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = self.model(data)[t]\n",
    "                loss_CE = self.criterion(output,target)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                (loss_CE).backward()\n",
    "                self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "\n",
    "            train_loss,train_acc = self.evaluator.evaluate(self.model, self.train_iterator, t, self.device)\n",
    "            num_batch = len(self.train_iterator)\n",
    "            print('| Epoch {:3d} | Train: loss={:.3f}, acc={:5.1f}% |'.format(epoch+1,train_loss,100*train_acc),end='')\n",
    "            test_loss,test_acc=self.evaluator.evaluate(self.model, self.test_iterator, t, self.device)\n",
    "            print(' Test: loss={:.3f}, acc={:5.1f}% |'.format(test_loss,100*test_acc),end='')\n",
    "            print()\n",
    "        \n",
    "    def criterion(self,output,targets):\n",
    "        \"\"\"\n",
    "        Arguments: output (The output logit of self.model), targets (Ground truth label)\n",
    "        Return: loss function for the regularization-based continual learning\n",
    "        \n",
    "        For the hyperparameter on regularization, please use self.lamb\n",
    "        \"\"\"\n",
    "        reg = 0\n",
    "        if self.t > 0:\n",
    "          for (name, param), (_, param_fixed) in zip(self.model.named_parameters(), self.model_fixed.named_parameters()):\n",
    "            reg += torch.sum(self.fisher[name] * (param - param_fixed).pow(2))\n",
    "        return self.ce(output, targets)+ self.lamb * reg    \n",
    "    \n",
    "    def compute_diag_fisher(self, device=None):\n",
    "        \"\"\"\n",
    "        Arguments: None. Just use global variables (self.model, self.criterion, ...)\n",
    "        Return: Diagonal Fisher matrix. \n",
    "        \n",
    "        This function will be used in the function 'update_fisher'\n",
    "        \"\"\"\n",
    "        fisher = {}\n",
    "        for (name, param) in self.model.named_parameters():\n",
    "          fisher[name] = 0 * param.data # torch.zeros_like(param)\n",
    "\n",
    "        # accumulate the diag of FIM\n",
    "        total = 0\n",
    "        for data, target in self.fisher_iterator:\n",
    "          \n",
    "          ######\n",
    "          # data, target = data.to(device), target.to(device)\n",
    "          ######\n",
    "\n",
    "          output = self.model(data)[self.t]\n",
    "          loss = self.ce(output, target)\n",
    "\n",
    "          self.model.zero_grad()\n",
    "          loss.backward()\n",
    "\n",
    "          for (name, param) in self.model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "              fisher[name] += param.grad.pow(2)\n",
    "\n",
    "          total += 1\n",
    "\n",
    "        # average\n",
    "        for (name, param) in self.model.named_parameters():\n",
    "          fisher[name] /= total \n",
    "\n",
    "        return fisher\n",
    "\n",
    "    def update_fisher(self, device):\n",
    "        \n",
    "        \"\"\"\n",
    "        Arguments: None. Just use global variables (self.model, self.fisher, ...)\n",
    "        Return: None. Just update the global variable self.fisher\n",
    "        Use 'compute_diag_fisher' to compute the fisher matrix\n",
    "        \n",
    "        hint : pytorch function\n",
    "        pseudo code\n",
    "        \"\"\"\n",
    "\n",
    "        fisher = self.compute_diag_fisher()\n",
    "        if self.t > 0:\n",
    "          for key in self.fisher.keys():\n",
    "            self.fisher[key] += fisher[key]\n",
    "        else:\n",
    "          self.fisher = fisher\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer object used for training\n",
    "myTrainer = Trainer(myModel, args, optimizer, t_classifier, task_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "\n",
    "utils.print_model_report(myModel)\n",
    "utils.print_optimizer_config(optimizer)\n",
    "print('-' * 100)\n",
    "\n",
    "# Loop tasks\n",
    "acc = np.zeros((len(task_info), len(task_info)), dtype=np.float32)\n",
    "lss = np.zeros((len(task_info), len(task_info)), dtype=np.float32)\n",
    "for t, ncla in task_info:\n",
    "    print(\"tasknum:\", t)\n",
    "    # Add new classes to the train, and test iterator\n",
    "\n",
    "    train_loader = train_dataset_loaders[t]\n",
    "    test_loader = test_dataset_loaders[t]\n",
    "    print(device)\n",
    "    myTrainer.train(train_loader, test_loader, t, device)\n",
    "\n",
    "    for u in range(t+1):\n",
    "        test_loader = test_dataset_loaders[u]\n",
    "        test_iterator = torch.utils.data.DataLoader(test_loader, 100, shuffle=False)\n",
    "        test_loss, test_acc = t_classifier.evaluate(myTrainer.model, test_iterator, u, device)\n",
    "        print('>>> Test on task {:2d}: loss={:.3f}, acc={:5.1f}% <<<'.format(u, test_loss, 100 * test_acc))\n",
    "        acc[t, u] = test_acc\n",
    "        lss[t, u] = test_loss\n",
    "\n",
    "    print('Average accuracy={:5.1f}%'.format(100 * np.mean(acc[t,:t+1])))\n",
    "\n",
    "    print('Save at ' + args['output_path'])\n",
    "    np.savetxt(args['output_path'], acc, '%.4f')\n",
    "    torch.save(myModel.state_dict(), './trained_model/' + log_name + '_task_{}.pt'.format(t))\n",
    "\n",
    "\n",
    "print('*' * 100)\n",
    "print('Accuracies =')\n",
    "for i in range(acc.shape[0]):\n",
    "    print('\\t', end='')\n",
    "    for j in range(acc.shape[1]):\n",
    "        print('{:5.1f}% '.format(100 * acc[i, j]), end='')\n",
    "    print()\n",
    "print('*' * 100)\n",
    "print('Done!')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_acc(file_name):\n",
    "    acc_arr = np.loadtxt(file_name)\n",
    "    avg_acc_arr = np.zeros(acc_arr.shape[1])\n",
    "    for i in range(acc_arr.shape[1]):\n",
    "        avg_acc_arr[i] = np.mean(acc_arr[i][:i+1])\n",
    "    \n",
    "    return avg_acc_arr\n",
    "filename = ''\n",
    "results = avg_acc(filename)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "task_num = args['tasknum']\n",
    "task = np.arange(task_num) +1\n",
    "ax = plt.subplot(111)\n",
    "    \n",
    "# for key in results.keys():\n",
    "ax.plot(task, results, label = 'ewc', linestyle = '-', marker = '.')\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "plt.xticks(task)\n",
    "\n",
    "plt.xlabel('Task',fontsize = 20)\n",
    "plt.ylabel('Accuracy',fontsize = 20)\n",
    "\n",
    "ax.legend(loc = 'center right', bbox_to_anchor=(1.3, 0.5))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
