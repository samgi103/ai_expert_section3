{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c299dc43",
      "metadata": {
        "id": "c299dc43"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "151a875b",
      "metadata": {
        "id": "151a875b"
      },
      "source": [
        "### hyper parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324e1655",
      "metadata": {
        "id": "324e1655"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "torch.manual_seed(777)\n",
        "\n",
        "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# 하이퍼 파라미터\n",
        "learning_rate = 0.001\n",
        "training_epochs = 40\n",
        "batch_size = 128\n",
        "quant_epoch = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b37e3d",
      "metadata": {
        "id": "41b37e3d"
      },
      "source": [
        "### dataset and data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb5a67c",
      "metadata": {
        "id": "eeb5a67c"
      },
      "outputs": [],
      "source": [
        "mnist_train = dsets.MNIST(\n",
        "    root=\"./\",  # 다운로드 경로 지정\n",
        "    train=True,  # True를 지정하면 훈련 데이터로 다운로드\n",
        "    transform=transforms.ToTensor(),  # 텐서로 변환\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "mnist_test = dsets.MNIST(\n",
        "    root=\"./\",  # 다운로드 경로 지정\n",
        "    train=False,  # False를 지정하면 테스트 데이터로 다운로드\n",
        "    transform=transforms.ToTensor(),  # 텐서로 변환\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e_IArBUcii2q",
      "metadata": {
        "id": "e_IArBUcii2q"
      },
      "source": [
        "### STE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-6Q3eP9OiiK6",
      "metadata": {
        "id": "-6Q3eP9OiiK6"
      },
      "outputs": [],
      "source": [
        "class roundpass(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ## Define output w.r.t. input\n",
        "        output = torch.round(input)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        ## Define grad_input w.r.t. grad_output\n",
        "        grad_input = grad_output\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "roundpass = roundpass.apply"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iLqpRmHzjxRZ",
      "metadata": {
        "id": "iLqpRmHzjxRZ"
      },
      "source": [
        "### Quantization module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A63Py1krzL1C",
      "metadata": {
        "id": "A63Py1krzL1C"
      },
      "outputs": [],
      "source": [
        "class Quantizer(nn.Module):\n",
        "    def __init__(self, bits=8, always_pos=False):\n",
        "        super(Quantizer, self).__init__()\n",
        "        \n",
        "        self.first = True\n",
        "        \n",
        "        self.alpha_baseline = nn.Parameter(\n",
        "            torch.zeros(1, device=device), requires_grad=False)\n",
        "        self.alpha_delta = nn.Parameter(\n",
        "            torch.zeros(1, device=device), requires_grad=True)\n",
        "\n",
        "        self.always_pos = always_pos\n",
        "     \n",
        "        self.Qp = 2**(bits-1) - 1\n",
        "        self.Qn = -self.Qp\n",
        "        self.num_steps = self.Qp - self.Qn\n",
        "\n",
        "    def get_alpha(self):\n",
        "        return F.softplus(self.alpha_baseline + self.alpha_delta)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.first:\n",
        "            def reverse_softplus(x):\n",
        "                return np.log(np.exp(x) - 1.0)\n",
        "\n",
        "            self.alpha_baseline.add_(reverse_softplus(x.std().item() * 3))\n",
        "            self.first = False\n",
        "\n",
        "        alpha = self.get_alpha()\n",
        "\n",
        "        step_size_r = 0.5 * self.num_steps * torch.reciprocal(alpha)\n",
        "        step_size = 2 * alpha / self.num_steps\n",
        "\n",
        "        if self.always_pos:\n",
        "            off = alpha\n",
        "        else:\n",
        "            off = 0\n",
        "\n",
        "        ## define q_x given x and other components above.\n",
        "        q_x = torch.clamp(roundpass((x - off) * step_size_r), self.Qn, self.Qp) * step_size + off\n",
        "        return q_x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X1f61Rgre3_d",
      "metadata": {
        "id": "X1f61Rgre3_d"
      },
      "source": [
        "### Quantization aware modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LSlkN56drpKa",
      "metadata": {
        "id": "LSlkN56drpKa"
      },
      "outputs": [],
      "source": [
        "class CustomConv2d(nn.Conv2d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(CustomConv2d, self).__init__(*args, **kwargs)\n",
        "        self.q_w = Quantizer()\n",
        "        self.q_a = Quantizer(always_pos=True)\n",
        "        self.is_quant = False # No quantization by default\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.is_quant:        \n",
        "          ## quantize the weights and inputs using the ``Quantize`` modules. \n",
        "          weight = self.q_w(self.weight)\n",
        "          inputs = self.q_a(x)\n",
        "      else:\n",
        "          weight = self.weight\n",
        "          inputs = x\n",
        "\n",
        "      return F.conv2d(\n",
        "          inputs,\n",
        "          weight,\n",
        "          bias=self.bias,\n",
        "          stride=self.stride,\n",
        "          padding=self.padding,\n",
        "          dilation=self.dilation,\n",
        "          groups=self.groups,\n",
        "      )\n",
        "\n",
        "\n",
        "class CustomLinear(nn.Linear):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(CustomLinear, self).__init__(*args, **kwargs)\n",
        "        self.q_w = Quantizer()\n",
        "        self.q_a = Quantizer(always_pos=True)\n",
        "        self.is_quant = False # No quantization by default\n",
        "\n",
        "    def forward(self, x):\n",
        "      if self.is_quant:        \n",
        "          ## quantize the weights and inputs using the ``Quantize`` modules. \n",
        "          weight = self.q_w(self.weight)\n",
        "          inputs = self.q_a(x)\n",
        "      else:\n",
        "          weight = self.weight\n",
        "          inputs = x\n",
        "\n",
        "      return F.linear(inputs, weight, bias=self.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a8a980",
      "metadata": {
        "id": "26a8a980"
      },
      "source": [
        "### neural network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9974d56",
      "metadata": {
        "id": "b9974d56"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv = CustomConv2d(1, 6, kernel_size=3, stride=1, padding=0, bias=False)\n",
        "        self.layer1 = nn.Sequential(\n",
        "            self.conv,\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fc1 = CustomLinear(4056, 30, bias=False)\n",
        "        self.fc2 = CustomLinear(30, 10, bias=False)\n",
        "        self.layer2 = nn.Sequential(self.fc1, torch.nn.ReLU(), self.fc2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.layer2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def6043a",
      "metadata": {
        "id": "def6043a"
      },
      "source": [
        "### custom function for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdab3971",
      "metadata": {
        "id": "bdab3971"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"weight\"):\n",
        "  os.mkdir('./weight')\n",
        "\n",
        "def eval_custom(model_, num_imgs):\n",
        "    with torch.no_grad():\n",
        "        X_test = (\n",
        "            mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "        )\n",
        "        Y_test = mnist_test.targets.to(device)\n",
        "        prediction = model_(X_test)\n",
        "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "        correct_prediction_100 = (\n",
        "            torch.argmax(prediction[:num_imgs], 1) == Y_test[:num_imgs]\n",
        "        )\n",
        "        accuracy = correct_prediction.float().mean()\n",
        "        accuracy_100 = correct_prediction_100.float().mean()\n",
        "        print(\"Accuracy_all:\", accuracy.item())\n",
        "        print(f\"Accuracy_{num_imgs}:\", accuracy_100.item())\n",
        "\n",
        "        torch.save(\n",
        "            model.state_dict(),\n",
        "            f\"./weight/model_{str(accuracy.item()):.7}_{str(accuracy_100.item()):.7}.pth\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c60fead",
      "metadata": {
        "id": "5c60fead"
      },
      "source": [
        "### iteration loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M5xy9jVcBQCA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5xy9jVcBQCA",
        "outputId": "bc725949-10f2-4606-bfaa-ce647da1445f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 배치의 수 : 468\n",
            "Accuracy_all: 0.8931999802589417\n",
            "Accuracy_100: 0.8899999856948853\n",
            "[Epoch:    1] cost = 0.530423105\n",
            "Accuracy_all: 0.9013999700546265\n",
            "Accuracy_100: 0.8899999856948853\n",
            "[Epoch:    2] cost = 0.432589144\n",
            "Accuracy_all: 0.9099999666213989\n",
            "Accuracy_100: 0.9099999666213989\n",
            "[Epoch:    3] cost = 0.389850825\n",
            "Accuracy_all: 0.9146999716758728\n",
            "Accuracy_100: 0.9399999976158142\n",
            "[Epoch:    4] cost = 0.358769208\n",
            "Accuracy_all: 0.9185000061988831\n",
            "Accuracy_100: 0.9300000071525574\n",
            "[Epoch:    5] cost = 0.335046858\n",
            "Accuracy_all: 0.9236999750137329\n",
            "Accuracy_100: 0.9300000071525574\n",
            "[Epoch:    6] cost = 0.31562832\n",
            "Accuracy_all: 0.9258999824523926\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:    7] cost = 0.299797207\n",
            "Accuracy_all: 0.9282999634742737\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:    8] cost = 0.285898119\n",
            "Accuracy_all: 0.9299999475479126\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:    9] cost = 0.273763508\n",
            "Accuracy_all: 0.9315999746322632\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   10] cost = 0.2632038\n",
            "Accuracy_all: 0.9335999488830566\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   11] cost = 0.253535837\n",
            "Accuracy_all: 0.9361000061035156\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   12] cost = 0.244721726\n",
            "Accuracy_all: 0.9375\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   13] cost = 0.236710727\n",
            "Accuracy_all: 0.9386000037193298\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   14] cost = 0.229082644\n",
            "Accuracy_all: 0.9405999779701233\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   15] cost = 0.222502604\n",
            "Accuracy_all: 0.9418999552726746\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   16] cost = 0.215831414\n",
            "Accuracy_all: 0.9430999755859375\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   17] cost = 0.210065857\n",
            "Accuracy_all: 0.9444999694824219\n",
            "Accuracy_100: 0.9599999785423279\n",
            "[Epoch:   18] cost = 0.204358503\n",
            "Accuracy_all: 0.9460999965667725\n",
            "Accuracy_100: 0.9699999690055847\n",
            "[Epoch:   19] cost = 0.198946804\n",
            "Accuracy_all: 0.9472000002861023\n",
            "Accuracy_100: 0.9599999785423279\n",
            "[Epoch:   20] cost = 0.194021091\n",
            "Accuracy_all: 0.9350999593734741\n",
            "Accuracy_100: 0.9399999976158142\n",
            "[Epoch:   21] cost = 0.189301729\n",
            "Accuracy_all: 0.9352999925613403\n",
            "Accuracy_100: 0.9399999976158142\n",
            "[Epoch:   22] cost = 0.184781268\n",
            "Accuracy_all: 0.9366999864578247\n",
            "Accuracy_100: 0.9399999976158142\n",
            "[Epoch:   23] cost = 0.180659786\n",
            "Accuracy_all: 0.936199963092804\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   24] cost = 0.176443115\n",
            "Accuracy_all: 0.9391999840736389\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   25] cost = 0.17249015\n",
            "Accuracy_all: 0.9386999607086182\n",
            "Accuracy_100: 0.9399999976158142\n",
            "[Epoch:   26] cost = 0.1688537\n",
            "Accuracy_all: 0.9395999908447266\n",
            "Accuracy_100: 0.9399999976158142\n",
            "[Epoch:   27] cost = 0.165305287\n",
            "Accuracy_all: 0.9409999847412109\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   28] cost = 0.161837652\n",
            "Accuracy_all: 0.9429999589920044\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   29] cost = 0.158076301\n",
            "Accuracy_all: 0.944599986076355\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   30] cost = 0.155165657\n",
            "Accuracy_all: 0.9440000057220459\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   31] cost = 0.152180642\n",
            "Accuracy_all: 0.9451999664306641\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   32] cost = 0.149434373\n",
            "Accuracy_all: 0.9447999596595764\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   33] cost = 0.146448895\n",
            "Accuracy_all: 0.9465000033378601\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   34] cost = 0.143933892\n",
            "Accuracy_all: 0.9477999806404114\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   35] cost = 0.141033411\n",
            "Accuracy_all: 0.9469999670982361\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   36] cost = 0.138713211\n",
            "Accuracy_all: 0.9484999775886536\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   37] cost = 0.136027575\n",
            "Accuracy_all: 0.9496999979019165\n",
            "Accuracy_100: 0.9599999785423279\n",
            "[Epoch:   38] cost = 0.133909672\n",
            "Accuracy_all: 0.9503999948501587\n",
            "Accuracy_100: 0.9599999785423279\n",
            "[Epoch:   39] cost = 0.13166599\n",
            "Accuracy_all: 0.949999988079071\n",
            "Accuracy_100: 0.949999988079071\n",
            "[Epoch:   40] cost = 0.129416674\n"
          ]
        }
      ],
      "source": [
        "model = CNN().to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)  # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=1.0, end_factor=1e-2, total_iters=training_epochs\n",
        ")\n",
        "\n",
        "total_batch = len(data_loader)\n",
        "print(\"총 배치의 수 : {}\".format(total_batch))\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    if epoch >= quant_epoch:\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "                m.is_quant=True\n",
        "\n",
        "    for X, Y in data_loader:  # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
        "        # image is already size of (28x28), no reshape\n",
        "        # label is not one-hot encoded\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "    eval_custom(model, 100)\n",
        "\n",
        "    print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
