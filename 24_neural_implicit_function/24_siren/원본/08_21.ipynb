{"cells":[{"cell_type":"markdown","metadata":{"id":"hUBqyXw4i9rG"},"source":["# SIREN 실습자료\n","\n","8월 21일 AI Expert 과정을 위해 제작된 colab입니다.\n","본 자료에서는 SIREN MLP의 특성 및 활용에 대해 탐구합니다. SIREN MLP에 관한 이론적 배경은 다음 논문을 참고해주세요. [Implicit Neural Activations with Periodic Activation Functions](https://vsitzmann.github.io/siren).\n","\n","본 실습은 다음의 순서로 구성되어 있습니다.\n","* Fitting an image\n","* Solving Poisson's equation\n","* Fitting SDF from Point Clouds\n","\n","**본 코랩 파일을 본인 계정의 구글 드라이브에 저장하시면 수정 후 저장이 가능합니다: 메뉴바의 File --> Save a copy in Drive**\n","\n","**GPU를 활성화하였는지 확인해주세요: 메뉴바의 Edit --> Notebook Setting --> T4 GPU 선택**"]},{"cell_type":"code","source":["# 서버 연결 테스트\n","print(\"hello world!\")"],"metadata":{"id":"9rotLa8hPZ5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GPU 연결 테스트\n","import torch\n","print(torch.cuda.is_available())"],"metadata":{"id":"UmCSk7c9Pkss"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mzjqBJoiBAfG"},"source":["# 0. 기본함수 정의"]},{"cell_type":"markdown","metadata":{"id":"kUel71wsDtsD"},"source":["#### 필요한 패키지 설치 및 라이브러리 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSjoD7xyDtsE"},"outputs":[],"source":["!pip install plyfile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUxbT1b7DtsF"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import os\n","\n","from PIL import Image\n","from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n","import numpy as np\n","import scipy\n","import skimage\n","import matplotlib.pyplot as plt\n","import logging\n","import plyfile\n","import skimage.measure\n","\n","import time"]},{"cell_type":"markdown","metadata":{"id":"HCSOaOmTDtsF"},"source":["좌표 grid를 생성하기 위한 함수를 정의합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4arW7Z7Ki9rJ"},"outputs":[],"source":["def get_mgrid(sidelen, dim=2):\n","    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n","    sidelen: int\n","    dim: int'''\n","    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n","    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n","    mgrid = mgrid.reshape(-1, dim)\n","    return mgrid"]},{"cell_type":"markdown","metadata":{"id":"0RUUS8LnBNpH"},"source":["differential operation을 수행하는 함수를 정의합니다. laplace, divergence, 그리고 gradient를 포함하며 이들은 pytorch의 autodiff를 통해 numerical하게 계산됩니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Xm2o-2UBTnX"},"outputs":[],"source":["def laplace(y, x):\n","    grad = gradient(y, x)\n","    return divergence(grad, x)\n","\n","def divergence(y, x):\n","    div = 0.\n","    for i in range(y.shape[-1]):\n","        div += torch.autograd.grad(y[..., i], x, torch.ones_like(y[..., i]), create_graph=True)[0][..., i:i+1]\n","    return div\n","\n","def gradient(y, x, grad_outputs=None):\n","    if grad_outputs is None:\n","        grad_outputs = torch.ones_like(y)\n","    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n","    return grad"]},{"cell_type":"markdown","metadata":{"id":"chTu7syzDFHT"},"source":["마지막으로, sine layer를 정의하고 이를 이용해 SIREN network를 구현합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wEnNh2JTi9rK"},"outputs":[],"source":["class SineLayer(nn.Module):\n","    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n","\n","    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the\n","    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a\n","    # hyperparameter.\n","\n","    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of\n","    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n","\n","    def __init__(self, in_features, out_features, bias=True,\n","                 is_first=False, omega_0=30):\n","        super().__init__()\n","        self.omega_0 = omega_0\n","        self.is_first = is_first\n","\n","        self.in_features = in_features\n","        self.linear = nn.Linear(in_features, out_features, bias=bias)\n","\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        with torch.no_grad():\n","            if self.is_first:\n","                self.linear.weight.uniform_(-1 / self.in_features,\n","                                             1 / self.in_features)\n","            else:\n","                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n","                                             np.sqrt(6 / self.in_features) / self.omega_0)\n","\n","    def forward(self, input):\n","        return torch.sin(self.omega_0 * self.linear(input))\n","\n","    def forward_with_intermediate(self, input):\n","        # For visualization of activation distributions\n","        intermediate = self.omega_0 * self.linear(input)\n","        return torch.sin(intermediate), intermediate\n","\n","class Siren(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False,\n","                 first_omega_0=30, hidden_omega_0=30.):\n","        super().__init__()\n","\n","        self.net = []\n","        self.net.append(SineLayer(in_features, hidden_features,\n","                                  is_first=True, omega_0=first_omega_0))\n","\n","        for i in range(hidden_layers):\n","            self.net.append(SineLayer(hidden_features, hidden_features,\n","                                      is_first=False, omega_0=hidden_omega_0))\n","\n","        if outermost_linear:\n","            final_linear = nn.Linear(hidden_features, out_features)\n","\n","            with torch.no_grad():\n","                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0,\n","                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n","\n","            self.net.append(final_linear)\n","        else:\n","            self.net.append(SineLayer(hidden_features, out_features,\n","                                      is_first=False, omega_0=hidden_omega_0))\n","\n","        self.net = nn.Sequential(*self.net)\n","\n","    def forward(self, coords):\n","        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n","        output = self.net(coords)\n","        return output, coords\n","\n","    def forward_with_activations(self, coords, retain_grad=False):\n","        '''Returns not only model output, but also intermediate activations.\n","        Only used for visualizing activations later!'''\n","        activations = OrderedDict()\n","\n","        activation_count = 0\n","        x = coords.clone().detach().requires_grad_(True)\n","        activations['input'] = x\n","        for i, layer in enumerate(self.net):\n","            if isinstance(layer, SineLayer):\n","                x, intermed = layer.forward_with_intermediate(x)\n","\n","                if retain_grad:\n","                    x.retain_grad()\n","                    intermed.retain_grad()\n","\n","                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n","                activation_count += 1\n","            else:\n","                x = layer(x)\n","\n","                if retain_grad:\n","                    x.retain_grad()\n","\n","            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n","            activation_count += 1\n","\n","        return activations"]},{"cell_type":"markdown","metadata":{"id":"ncL598k9i9rL"},"source":["<a id='section_1'></a>\n","## 1. Fitting an image\n","\n","본 section에서는 SIREN 함수 $\\Phi(x)$로 grayscale image $f(x)$를 parametrize합니다. 이 때, $x$는 pixel coordinate을 의미합니다.\n","\n","이를 위해 다음의 손실함수로 $\\Phi$를 최적화합니다:\n","$$L=\\int_{\\Omega} \\lVert \\Phi(\\mathbf{x}) - f(\\mathbf{x}) \\rVert\\mathrm{d}\\mathbf{x},$$ 이 때, $\\Omega$는 이미지의 도메인을 의미합니다."]},{"cell_type":"markdown","metadata":{"id":"FM5bE5S_GIrC"},"source":["#### Define a pytorch dataset for fitting an image\n","cameraman image(scikit-image library에서 제공하는 예시 이미지)에서 각 픽셀의 좌표와 그에 해당하는 grayscale color의 pair를 return하는 pytorch dataset을 정의합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-D3fCcMlDtsI"},"outputs":[],"source":["plt.imshow(skimage.data.camera())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ts_R2vu5i9rM"},"outputs":[],"source":["def get_cameraman_tensor(sidelength):\n","    img = Image.fromarray(skimage.data.camera())\n","    transform = Compose([\n","        Resize(sidelength),\n","        ToTensor(),\n","        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n","    ])\n","    img = transform(img)\n","    return img\n","\n","class ImageFitting(Dataset):\n","    def __init__(self, sidelength):\n","        super().__init__()\n","        img = get_cameraman_tensor(sidelength)\n","        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n","        self.coords = get_mgrid(sidelength, 2)\n","\n","    def __len__(self):\n","        return 1\n","\n","    def __getitem__(self, idx):\n","        if idx > 0: raise IndexError\n","\n","        return self.coords, self.pixels"]},{"cell_type":"markdown","metadata":{"id":"hH_8kFnwi9rM","pycharm":{"name":"#%% md\n"}},"source":["#### Instantiate a dataset and a SIREN model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mroLvWvli9rM"},"outputs":[],"source":["cameraman = ImageFitting(256)\n","dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)\n","\n","img_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n","                  hidden_layers=3, outermost_linear=True)\n","img_siren.cuda()"]},{"cell_type":"markdown","metadata":{"id":"YAhsenT2i9rM"},"source":["#### Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAvc-BSWi9rM"},"outputs":[],"source":["total_steps = 500 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n","steps_til_summary = 10\n","\n","optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n","\n","model_input, ground_truth = next(iter(dataloader))\n","model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n","\n","for step in range(total_steps):\n","    model_output, coords = img_siren(model_input)\n","    loss = ((model_output - ground_truth)**2).mean()\n","\n","    if not step % steps_til_summary:\n","        print(\"Step %d, Total loss %0.6f\" % (step, loss))\n","        img_grad = gradient(model_output, coords)\n","        img_laplacian = laplace(model_output, coords)\n","\n","        fig, axes = plt.subplots(1,3, figsize=(18,6))\n","        axes[0].imshow(model_output.cpu().view(256,256).detach().numpy())\n","        axes[1].imshow(img_grad.norm(dim=-1).cpu().view(256,256).detach().numpy())\n","        axes[2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\n","        plt.show()\n","\n","    optim.zero_grad()\n","    loss.backward()\n","    optim.step()"]},{"cell_type":"markdown","metadata":{"id":"MAayGlNAO8Kc"},"source":["### Quiz 1: Comparision to the baseline model\n","- ReLU를 activation으로 활용하는 baseline 모델을 구현하세요.\n","- 구현된 Baseline 모델을 학습시키고 그 결과를 SIREN과 비교해보세요.\n","- Initialization은 pytorch 기본 initialization을 사용합니다. (SIREN처럼 명시적으로 initialize시킬 필요가 없습니다.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCReiwaqPwqj"},"outputs":[],"source":["class ReLULayer(nn.Module):\n","\n","    def __init__(self, in_features, out_features, bias=True,\n","                 is_first=False):\n","        super().__init__()\n","        self.is_first = is_first\n","\n","        self.in_features = in_features\n","\n","        ######## Implement from here ########\n","        raise NotImplementedError\n","\n","        ####### End of Implementation #######\n","\n","    def forward(self, input):\n","        return self.relu(self.linear(input))\n","\n","class ReLUBaseline(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False):\n","        super().__init__()\n","\n","        self.net = []\n","        ######## Implement from here ########\n","        raise NotImplementedError\n","\n","        ####### End of Implementation #######\n","\n","        self.net = nn.Sequential(*self.net)\n","\n","    def forward(self, coords):\n","        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n","        output = self.net(coords)\n","        return output, coords\n","\n","### Instantiate dataset and the baseline model\n","cameraman = ImageFitting(256)\n","dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)\n","\n","relu_baseline = ReLUBaseline(in_features=2, out_features=1, hidden_features=256,\n","                        hidden_layers=3, outermost_linear=True)\n","relu_baseline.cuda()\n","\n","### Training loop\n","total_steps = 500 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n","steps_til_summary = 10\n","\n","optim = torch.optim.Adam(lr=1e-4, params=relu_baseline.parameters())\n","\n","model_input, ground_truth = next(iter(dataloader))\n","model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n","\n","for step in range(total_steps):\n","    model_output, coords = relu_baseline(model_input)\n","    loss = ((model_output - ground_truth)**2).mean()\n","\n","    if not step % steps_til_summary:\n","        print(\"Step %d, Total loss %0.6f\" % (step, loss))\n","        img_grad = gradient(model_output, coords)\n","        img_laplacian = laplace(model_output, coords)\n","\n","        fig, axes = plt.subplots(1,3, figsize=(18,6))\n","        axes[0].imshow(model_output.cpu().view(256,256).detach().numpy())\n","        axes[1].imshow(img_grad.norm(dim=-1).cpu().view(256,256).detach().numpy())\n","        axes[2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\n","        plt.show()\n","\n","    optim.zero_grad()\n","    loss.backward()\n","    optim.step()"]},{"cell_type":"markdown","metadata":{"id":"7NeDZnt4i9rP"},"source":["<a id='section_3'></a>\n","## 2. Solving Poisson's equation\n","\n","본 섹션에서는 이미지의 gradient 정보만 주어졌을 때 원본 이미지를 복원하는 방법에 대해서 다룹니다.\n","\n","이를 위해 다음의 손실함수로 $\\Phi$를 최적화합니다:\n","$$L=\\int_{\\Omega} \\lVert \\nabla\\Phi(\\mathbf{x}) - \\nabla f(\\mathbf{x}) \\rVert\\mathrm{d}\\mathbf{x},$$ 이 때, $\\Omega$는 이미지의 도메인을 의미합니다."]},{"cell_type":"markdown","metadata":{"id":"pD3RX1-fi9rQ","pycharm":{"name":"#%% md\n"}},"source":["#### Define the loss function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2BhxXwEi9rQ","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["def gradients_mse(model_output, coords, gt_gradients):\n","    # compute gradients on the model\n","    gradients = gradient(model_output, coords)\n","    # compare them with the ground-truth\n","    gradients_loss = torch.mean((gradients - gt_gradients).pow(2).sum(-1))\n","    return gradients_loss"]},{"cell_type":"markdown","metadata":{"id":"vcnz1Y8tDtsK"},"source":["#### Define a pytorch dataset for solving Possion equation\n","Section 1과 마찬가지로 cameraman image를 사용합니다. 아래의 데이터셋은 각 픽셀의 좌표와 그에 해당하는 grayscale color, gradient, 그리고 laplace를 return합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IbMkZsw7i9rP","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import scipy.ndimage\n","\n","class PoissonEqn(Dataset):\n","    def __init__(self, sidelength):\n","        super().__init__()\n","        img = get_cameraman_tensor(sidelength)\n","\n","        # Compute gradient and laplacian\n","        grads_x = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)[..., None]\n","        grads_y = scipy.ndimage.sobel(img.numpy(), axis=2).squeeze(0)[..., None]\n","        grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n","\n","        self.grads = torch.stack((grads_x, grads_y), dim=-1).view(-1, 2)\n","        self.laplace = scipy.ndimage.laplace(img.numpy()).squeeze(0)[..., None]\n","        self.laplace = torch.from_numpy(self.laplace)\n","\n","        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n","        self.coords = get_mgrid(sidelength, 2)\n","\n","    def __len__(self):\n","        return 1\n","\n","    def __getitem__(self, idx):\n","        return self.coords, {'pixels':self.pixels, 'grads':self.grads, 'laplace':self.laplace}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HI0RAkY1DtsK"},"outputs":[],"source":["img = get_cameraman_tensor(256)\n","\n","grads_x = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)[..., None]\n","grads_y = scipy.ndimage.sobel(img.numpy(), axis=2).squeeze(0)[..., None]\n","grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n","\n","fig, axes = plt.subplots(1,2, figsize=(12,6))\n","axes[0].imshow(grads_x)\n","axes[1].imshow(grads_y)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"uDYETmb0i9rP","pycharm":{"name":"#%% md\n"}},"source":["#### Instantiate a dataset and a SIREN model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vo0AD2Vhi9rQ","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["cameraman_poisson = PoissonEqn(128)\n","dataloader = DataLoader(cameraman_poisson, batch_size=1, pin_memory=True, num_workers=0)\n","\n","poisson_siren = Siren(in_features=2, out_features=1, hidden_features=256,\n","                      hidden_layers=3, outermost_linear=True)\n","poisson_siren.cuda()"]},{"cell_type":"markdown","metadata":{"id":"jcAkujrWi9rQ","pycharm":{"name":"#%% md\n"}},"source":["#### Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97wYu7hCi9rR","pycharm":{"is_executing":true,"name":"#%%\n"}},"outputs":[],"source":["total_steps = 1000\n","steps_til_summary = 10\n","\n","optim = torch.optim.Adam(lr=1e-4, params=poisson_siren.parameters())\n","\n","model_input, gt = next(iter(dataloader))\n","gt = {key: value.cuda() for key, value in gt.items()}\n","model_input = model_input.cuda()\n","\n","for step in range(total_steps):\n","    start_time = time.time()\n","\n","    model_output, coords = poisson_siren(model_input)\n","    train_loss = gradients_mse(model_output, coords, gt['grads'])\n","\n","    if not step % steps_til_summary:\n","        print(\"Step %d, Total loss %0.6f, iteration time %0.6f\" % (step, train_loss, time.time() - start_time))\n","\n","        img_grad = gradient(model_output, coords)\n","        img_laplacian = laplace(model_output, coords)\n","\n","        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n","        axes[0].imshow(model_output.cpu().view(128,128).detach().numpy())\n","        axes[1].imshow(img_grad.cpu().norm(dim=-1).view(128,128).detach().numpy())\n","        axes[2].imshow(img_laplacian.cpu().view(128,128).detach().numpy())\n","        plt.show()\n","\n","    optim.zero_grad()\n","    train_loss.backward()\n","    optim.step()"]},{"cell_type":"markdown","metadata":{"id":"dQPU_Wl8MSls"},"source":["#### out-of-range behavior\n","out-of-range 도메인에서 SIREN은 어떻게 학습되었을까요? 아래 코드는 학습 도메인인 [-1, +1] 범위가 아닌 [-50, +50] 범위에서 샘플링된 SIREN의 결과값을 보여줍니다.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLa87Cr6M7wf"},"outputs":[],"source":["with torch.no_grad():\n","    out_of_range_coords = get_mgrid(1024, 2) * 50\n","    model_out, _ = poisson_siren(out_of_range_coords.cuda())\n","\n","    fig, ax = plt.subplots(figsize=(16,16))\n","    ax.imshow(model_out.cpu().view(1024,1024).numpy())\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"BJuHX1ubNPs9"},"source":["### Quiz 2: Zoom in\n","- 입력 도메인에서 특정 부분만을 집중적으로 샘플링하여 이미지를 완성하세요.\n","- [-0.5, -0.5] ~ [0.5, 0.5]의 범위에서 size=128의 grid를 샘플링하여 이미지를 완성하세요.\n","- [-0.5, -0.5] ~ [0.5, 0.5]의 범위에서 size=1024의 grid를 샘플링하여 이미지를 완성하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKkPkosWNTf6"},"outputs":[],"source":["with torch.no_grad():\n","    ######## Implement from here ########\n","    raise NotImplementedError\n","\n","    ####### End of Implementation #######\n","\n","    fig, ax = plt.subplots(1, 2, figsize=(12,6))\n","    ax[0].imshow(model_out_256.cpu().view(128,128).numpy())\n","    ax[1].imshow(model_out_1024.cpu().view(1024,1024).numpy())\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Yt4XmdSO0GQn"},"source":["### Quiz 3: Possion Image Editing"]},{"cell_type":"markdown","metadata":{"id":"Hu3Jx_uVSaJf"},"source":["## 3. Fitting SDF from Point Clouds\n","\n","\n","본 섹션에서는 point cloud가 주어졌을 때 이로부터 3차원 surface를 복원하는 방법에 대해 다룹니다.\n","3차원 surface는 Signed Distance Field (SDF) $\\Phi: x \\rightarrow s$로 표현됩니다. 이 때, $x$는 3차원 좌표, $s$는 surface까지의 거리를 의미합니다.\n","\n","이를 위해 다음의 손실함수 $\\mathcal{L}$로 $\\Phi$를 최적화합니다:\n","$$\\mathcal{L}=\\int_{\\Omega} \\lVert |\\nabla\\Phi(x)| - 1 \\rVert\\mathrm{d}\\mathbf{x} + \\int_{\\Omega_0}\\lVert\\Phi(x)\\rVert + (1-\\nabla\\Phi(x) \\cdot n(x))\\mathrm{d}\\mathbf{x} + \\int_{\\Omega\\setminus\\Omega_0} \\Psi(\\Phi(x))\\mathrm{d}\\mathbf{x}$$"]},{"cell_type":"markdown","metadata":{"id":"v9qaeAP_1TN1"},"source":["#### Define the loss function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0JlLS-p1I6a"},"outputs":[],"source":["def sdf_loss(pred_sdf, coords, gt_sdf, gt_normals):\n","    '''\n","       x: batch of input coordinates\n","       y: usually the output of the trial_soln function\n","       '''\n","\n","    _gradient = gradient(pred_sdf, coords)\n","\n","    # Wherever boundary_values is not equal to zero, we interpret it as a boundary constraint.\n","    sdf_constraint = torch.where(gt_sdf != -1, pred_sdf, torch.zeros_like(pred_sdf))\n","    inter_constraint = torch.where(gt_sdf != -1, torch.zeros_like(pred_sdf), torch.exp(-1e2 * torch.abs(pred_sdf)))\n","    normal_constraint = torch.where(gt_sdf != -1, 1 - F.cosine_similarity(_gradient, gt_normals, dim=-1)[..., None],\n","                                    torch.zeros_like(_gradient[..., :1]))\n","    grad_constraint = torch.abs(_gradient.norm(dim=-1) - 1)\n","    return {'sdf': torch.abs(sdf_constraint).mean() * 3e3,\n","            'inter': inter_constraint.mean() * 1e2,\n","            'normal_constraint': normal_constraint.mean() * 1e2,\n","            'grad_constraint': grad_constraint.mean() * 5e1}"]},{"cell_type":"markdown","metadata":{"id":"Xo_7pXha1a8z"},"source":["#### Define Pytorch Dataset\n","\n","* 데이터셋으로는 3D Stanford Model의 Thai Statue를 사용합니다. ([download link](https://drive.google.com/drive/folders/1_iq__37-hw7FJOEUK1tX7mdp8SKB368K))\n","* 'thai_statue.xyz'를 다운로드 받은 후, 이를 colab의 가장 상위 폴더에 저장해주세요.\n","* xyz file의 visualization은 MeshLab([link](https://www.meshlab.net/))을 통해 가능합니다.\n","* 아래의 데이터셋은 입력 point cloud로부터 on_surface_points만큼의 포인트를 샘플링하고, 전체 도메인으로부터 같은 개수의 포인트를 샘플링하여, 해당 포인트의 SDF와 Normal값을 함께 return합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U8aozp0KSgdf"},"outputs":[],"source":["class PointCloud(Dataset):\n","    def __init__(self, on_surface_points, keep_aspect_ratio=True):\n","        super().__init__()\n","\n","        print(\"Loading point cloud\")\n","        point_cloud = np.genfromtxt('./thai_statue.xyz')\n","        print(\"Finished loading point cloud\")\n","\n","        coords = point_cloud[:, :3]\n","        self.normals = point_cloud[:, 3:]\n","\n","        # Reshape point cloud such that it lies in bounding box of (-1, 1) (distorts geometry, but makes for high\n","        # sample efficiency)\n","        coords -= np.mean(coords, axis=0, keepdims=True)\n","        if keep_aspect_ratio:\n","            coord_max = np.amax(coords)\n","            coord_min = np.amin(coords)\n","        else:\n","            coord_max = np.amax(coords, axis=0, keepdims=True)\n","            coord_min = np.amin(coords, axis=0, keepdims=True)\n","\n","        self.coords = (coords - coord_min) / (coord_max - coord_min)\n","        self.coords -= 0.5\n","        self.coords *= 2.\n","\n","        self.on_surface_points = on_surface_points\n","\n","    def __len__(self):\n","        return self.coords.shape[0] // self.on_surface_points\n","\n","    def __getitem__(self, idx):\n","        point_cloud_size = self.coords.shape[0]\n","\n","        off_surface_samples = self.on_surface_points  # **2\n","        total_samples = self.on_surface_points + off_surface_samples\n","\n","        # Random coords\n","        rand_idcs = np.random.choice(point_cloud_size, size=self.on_surface_points)\n","\n","        on_surface_coords = self.coords[rand_idcs, :]\n","        on_surface_normals = self.normals[rand_idcs, :]\n","\n","        off_surface_coords = np.random.uniform(-1, 1, size=(off_surface_samples, 3))\n","        off_surface_normals = np.ones((off_surface_samples, 3)) * -1\n","\n","        sdf = np.zeros((total_samples, 1))  # on-surface = 0\n","        sdf[self.on_surface_points:, :] = -1  # off-surface = -1\n","\n","        coords = np.concatenate((on_surface_coords, off_surface_coords), axis=0)\n","        normals = np.concatenate((on_surface_normals, off_surface_normals), axis=0)\n","\n","        return {'coords': torch.from_numpy(coords).float()}, {'sdf': torch.from_numpy(sdf).float(),\n","                                                              'normals': torch.from_numpy(normals).float()}"]},{"cell_type":"markdown","metadata":{"id":"XEFkrk62XC4H"},"source":["#### Instantiate a dataset and a SIREN model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vp0abYidWALn"},"outputs":[],"source":["thai_statue = PointCloud(250000)\n","dataloader = DataLoader(thai_statue, batch_size=1, pin_memory=True, num_workers=0)\n","\n","sdf_siren = Siren(in_features=3, out_features=1, hidden_features=256,\n","                  hidden_layers=3, outermost_linear=True)\n","sdf_siren.cuda()"]},{"cell_type":"markdown","metadata":{"id":"dBf30zlsDtsM"},"source":["#### Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohnoRjjEYs3X","scrolled":true},"outputs":[],"source":["### Training loop\n","total_steps = 2000\n","steps_til_summary = 10\n","\n","optim = torch.optim.Adam(lr=1e-4, params=sdf_siren.parameters())\n","\n","\n","for step in range(total_steps):\n","    model_input, ground_truth = next(iter(dataloader))\n","    model_input, sdf_gt, normals_gt = model_input['coords'].cuda(), ground_truth['sdf'].cuda(), ground_truth['normals'].cuda()\n","    sdf_pred, coords = sdf_siren(model_input)\n","    losses = sdf_loss(sdf_pred, coords, sdf_gt, normals_gt)\n","    train_loss = 0\n","    log_message = \"Step %d, \" % step\n","    for loss_name, loss in losses.items():\n","        single_loss = loss.mean()\n","        train_loss += single_loss\n","        log_message += (\"%s %0.2f, \" % (loss_name, single_loss.item()))\n","\n","    if not step % steps_til_summary:\n","        #print(\"Step %d, Total loss %0.6f\" % (step, train_loss))\n","        log_message += \"Total loss %0.6f\" % (train_loss)\n","        print(log_message)\n","\n","    optim.zero_grad()\n","    train_loss.backward()\n","    optim.step()"]},{"cell_type":"markdown","metadata":{"id":"ToYtVVzMDtsM"},"source":["#### Extract a mesh from a SDF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gos7VN58eP0N"},"outputs":[],"source":["import logging\n","import plyfile\n","import skimage.measure\n","\n","\n","def create_mesh(\n","    decoder, filename, N=256, max_batch=64 ** 3, offset=None, scale=None\n","):\n","    start = time.time()\n","    ply_filename = filename\n","\n","    decoder.eval()\n","\n","    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n","    voxel_origin = [-1, -1, -1]\n","    voxel_size = 2.0 / (N - 1)\n","\n","    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n","    samples = torch.zeros(N ** 3, 4)\n","\n","    # transform first 3 columns\n","    # to be the x, y, z index\n","    samples[:, 2] = overall_index % N\n","    samples[:, 1] = (overall_index.long() / N) % N\n","    samples[:, 0] = ((overall_index.long() / N) / N) % N\n","\n","    # transform first 3 columns\n","    # to be the x, y, z coordinate\n","    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n","    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n","    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n","\n","    num_samples = N ** 3\n","\n","    samples.requires_grad = False\n","\n","    head = 0\n","\n","    while head < num_samples:\n","        print(head)\n","        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()\n","\n","        samples[head : min(head + max_batch, num_samples), 3] = (\n","            decoder(sample_subset)[0]\n","            .squeeze()#.squeeze(1)\n","            .detach()\n","            .cpu()\n","        )\n","        head += max_batch\n","\n","    sdf_values = samples[:, 3]\n","    sdf_values = sdf_values.reshape(N, N, N)\n","\n","    end = time.time()\n","    print(\"sampling takes: %f\" % (end - start))\n","\n","    convert_sdf_samples_to_ply(\n","        sdf_values.data.cpu(),\n","        voxel_origin,\n","        voxel_size,\n","        ply_filename + \".ply\",\n","        offset,\n","        scale,\n","    )\n","\n","\n","def convert_sdf_samples_to_ply(\n","    pytorch_3d_sdf_tensor,\n","    voxel_grid_origin,\n","    voxel_size,\n","    ply_filename_out,\n","    offset=None,\n","    scale=None,\n","):\n","    \"\"\"\n","    Convert sdf samples to .ply\n","\n","    :param pytorch_3d_sdf_tensor: a torch.FloatTensor of shape (n,n,n)\n","    :voxel_grid_origin: a list of three floats: the bottom, left, down origin of the voxel grid\n","    :voxel_size: float, the size of the voxels\n","    :ply_filename_out: string, path of the filename to save to\n","\n","    This function adapted from: https://github.com/RobotLocomotion/spartan\n","    \"\"\"\n","\n","    start_time = time.time()\n","\n","    numpy_3d_sdf_tensor = pytorch_3d_sdf_tensor.numpy()\n","\n","    verts, faces, normals, values = np.zeros((0, 3)), np.zeros((0, 3)), np.zeros((0, 3)), np.zeros(0)\n","    verts, faces, normals, values = skimage.measure.marching_cubes(\n","        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3\n","    )\n","\n","    # transform from voxel coordinates to camera coordinates\n","    # note x and y are flipped in the output of marching_cubes\n","    mesh_points = np.zeros_like(verts)\n","    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n","    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n","    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n","\n","    # apply additional offset and scale\n","    if scale is not None:\n","        mesh_points = mesh_points / scale\n","    if offset is not None:\n","        mesh_points = mesh_points - offset\n","\n","    # try writing to the ply file\n","\n","    num_verts = verts.shape[0]\n","    num_faces = faces.shape[0]\n","\n","    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n","\n","    for i in range(0, num_verts):\n","        verts_tuple[i] = tuple(mesh_points[i, :])\n","\n","    faces_building = []\n","    for i in range(0, num_faces):\n","        faces_building.append(((faces[i, :].tolist(),)))\n","    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n","\n","    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n","    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n","\n","    ply_data = plyfile.PlyData([el_verts, el_faces])\n","    logging.debug(\"saving mesh to %s\" % (ply_filename_out))\n","    ply_data.write(ply_filename_out)\n","\n","    logging.debug(\n","        \"converting to ply format and writing to file took {} s\".format(\n","            time.time() - start_time\n","        )\n","    )"]},{"cell_type":"markdown","metadata":{"id":"1yOn4yAsDtsM"},"source":["학습된 SDF로부터 mesh를 추출하고 이를 result.ply로 저장합니다. 이를 로컬컴퓨터로 다운받아 meshlab으로 visualize할 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pk-Va2NAc3kB"},"outputs":[],"source":["create_mesh(sdf_siren, './result')"]},{"cell_type":"markdown","metadata":{"id":"9WpMnjlWmM8v"},"source":["### Quiz 3: Fitting SDF without supervision of normal\n","* Normal에 대한 supervision 없이 SDF를 fitting할 수 있을지 예측해보세요.\n","* Normal에 대한 supervision 없이 SIREN을 학습하고 결과값을 비교해보세요."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBKmPCntDtsM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/vsitzmann/siren/blob/master/explore_siren.ipynb","timestamp":1692450320919}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"nbformat":4,"nbformat_minor":0}