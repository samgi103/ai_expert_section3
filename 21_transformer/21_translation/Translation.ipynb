{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1fjtdevYjZTGjLKW0t8Ax2DZm_Ka3PNR_","timestamp":1691987434628},{"file_id":"1FC65ve-l_YqzWs7gNs4zTCAjwUiBrcCn","timestamp":1604048342097}],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"61da974aadf445d484edb149399d5630":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b71b202e24e34574aca8e007e6f982d4","IPY_MODEL_4310c7c2f04d4c1497a6dbeb3ae83012","IPY_MODEL_6234f5aaacd443b58fefb755a3743039"],"layout":"IPY_MODEL_98be2c51e5794b31bc465fdd4621ab60"}},"b71b202e24e34574aca8e007e6f982d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_115b7682e73444e58522a755b4c65734","placeholder":"​","style":"IPY_MODEL_3e4eb9980cd941f882f9d6a0233bb96f","value":"  0%"}},"4310c7c2f04d4c1497a6dbeb3ae83012":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f5743fff6b54497b02b75b612be6954","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b88373cd4bc4a5d9d842723a51dc5de","value":0}},"6234f5aaacd443b58fefb755a3743039":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4535a8c99966498a89e78458342d1300","placeholder":"​","style":"IPY_MODEL_82c688532f8847d8a1ac9c1c77e4d8d6","value":" 0/20 [00:03&lt;?, ?it/s]"}},"98be2c51e5794b31bc465fdd4621ab60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"115b7682e73444e58522a755b4c65734":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e4eb9980cd941f882f9d6a0233bb96f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f5743fff6b54497b02b75b612be6954":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b88373cd4bc4a5d9d842723a51dc5de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4535a8c99966498a89e78458342d1300":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82c688532f8847d8a1ac9c1c77e4d8d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f2ad7ab85724407b69a7f9577d67896":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6a2fbeedc5c460da10b6946de0804f5","IPY_MODEL_89e3f5f0cc4c496985310a79a45a247f","IPY_MODEL_704ad48274614221b1a55bb129fad1a8"],"layout":"IPY_MODEL_15cfce1b9a714942a6cf920099737f0f"}},"d6a2fbeedc5c460da10b6946de0804f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19ea6857bf242a3840d1eab56a5f84b","placeholder":"​","style":"IPY_MODEL_a144217eb62843268c42110179dfe8e6","value":"  0%"}},"89e3f5f0cc4c496985310a79a45a247f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_67ef7a16c0d34be9a99137345ffc8cc4","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f858beb308f74ef59e7e3719e73a6a2a","value":0}},"704ad48274614221b1a55bb129fad1a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a20eea636974000b9383e4392325816","placeholder":"​","style":"IPY_MODEL_595c1f4fd46c4a4bbe605e34423f165d","value":" 0/20 [00:00&lt;?, ?it/s]"}},"15cfce1b9a714942a6cf920099737f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d19ea6857bf242a3840d1eab56a5f84b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a144217eb62843268c42110179dfe8e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67ef7a16c0d34be9a99137345ffc8cc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f858beb308f74ef59e7e3719e73a6a2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a20eea636974000b9383e4392325816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"595c1f4fd46c4a4bbe605e34423f165d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"AYXIHngPoI2W"},"source":["# Neural Machine Translation with Various Sequence Models\n","\n","## Instructions\n","- In this project, we will perform Neural Machine Translation with recurrent neural networks and attention based models on Multi30k dataset which include language pairs of German and English.\n","- To this end, you need to implement necessary network components (e.g. LSTMCell, Multi-head attention) using nn.Module class and complete whole models with those modules. Then, you will experiment those network architectures and report Bilingual Evaluation Understudy (BLEU) on the test set.\n","- Fill in the section marked **Px.x** with the appropriate code. **You can only modify inside those areas, and not the skeleton code.**\n","- To begin, you should download this ipynb file into your own Google drive clicking `make a copy(사본만들기)`. Find the copy in your drive, change their name to `Translation.ipynb`, if their names were changed to e.g. `Copy of Translation.ipynb` or `Translationipynb의 사본`.\n","- <font color=\"red\">You'll be training large models. We recommend you to create at least **1GB** of space available on your Google drive to run everything properly.</font>"]},{"cell_type":"markdown","metadata":{"id":"x1ZGXqrvlc_O"},"source":["---\n","# Prerequisite: Mount your gdrive."]},{"cell_type":"code","metadata":{"id":"a0HEy2Tok-2u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691987657788,"user_tz":-540,"elapsed":31454,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"bc0e832c-aebc-402a-931a-d03e3bbbcf01"},"source":["# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n","# login with your google account and type authorization code to mount on your googlbie drive.\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"_Tsq4xR-liMH"},"source":["---\n","# Prerequisite: Setup the `root` directory properly."]},{"cell_type":"code","metadata":{"id":"SHzfVbfmloDz","executionInfo":{"status":"ok","timestamp":1691987679887,"user_tz":-540,"elapsed":480,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["# Specify the directory path where `Translation.ipynb` exists.\n","# For example, if you saved `Translation.ipynb` in `/gdrive/My Drive/samsung_ai` directory,\n","# then set root = '/gdrive/My Drive/samsung_ai'\n","# G:\\내 드라이브\\ai_expert\\18_translation\n","root = '/gdrive/My Drive/ai_expert/18_translation'"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ekROPNvqvBr"},"source":["---\n","# Prerequisite: Install libraries.\n","You only have to run this cell once per VM at startup."]},{"cell_type":"code","metadata":{"id":"xpWbZsp2quKI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691987725191,"user_tz":-540,"elapsed":40845,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"39dddc54-dbf9-4e21-81db-92ace651ee35"},"source":["!pip install torchtext==0.6.0\n","!pip install spacy\n","!python -m spacy download en\n","!python -m spacy download de"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m61.4/64.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Collecting sentencepiece (from torchtext==0.6.0)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.27.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n","Installing collected packages: sentencepiece, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.15.2\n","    Uninstalling torchtext-0.15.2:\n","      Successfully uninstalled torchtext-0.15.2\n","Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.11)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.1.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.5.0)\n","Requirement already satisfied: pydantic-core==2.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.4.0)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.1)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n","2023-08-14 04:35:00.407042: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-08-14 04:35:01.392207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-08-14 04:35:03.045127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-14 04:35:03.045747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-14 04:35:03.045981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n","full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n","Collecting en-core-web-sm==3.6.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.11)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)\n","Requirement already satisfied: pydantic-core==2.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.0)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.1)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","2023-08-14 04:35:14.261255: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-08-14 04:35:15.235501: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-08-14 04:35:17.004523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-14 04:35:17.005144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-08-14 04:35:17.005352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n","full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n","Collecting de-core-news-sm==3.6.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.6.0/de_core_news_sm-3.6.0-py3-none-any.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.6.0) (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.11)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.4.7)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.9)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.10.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (6.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.66.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.1.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (23.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.5.0)\n","Requirement already satisfied: pydantic-core==2.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.4.0)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.1.1)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.1.3)\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-3.6.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n"]}]},{"cell_type":"markdown","metadata":{"id":"9XDVC3lJl1_H"},"source":["---\n","# Basic settings"]},{"cell_type":"markdown","metadata":{"id":"3jIiyjEGlwJ8"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"eGlC_yM9lvue","executionInfo":{"status":"ok","timestamp":1691987744319,"user_tz":-540,"elapsed":10308,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["import os\n","import numpy as np\n","import time\n","from pathlib import Path\n","import torch\n","import torch.nn as nn\n","from torch.nn.parameter import Parameter\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.optim import SGD\n","import torchtext\n","from torchtext.datasets import Multi30k\n","from torchtext.data import Field, BucketIterator\n","from torchtext.data.utils import get_tokenizer\n","from torchtext import data\n","from torchtext.data.metrics import bleu_score\n","import spacy\n","from spacy.symbols import ORTH\n","import math\n","import random\n","import tqdm.notebook as tq\n","import copy"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W27cdKyEmJy1"},"source":["## Set Hyperparameters"]},{"cell_type":"code","metadata":{"id":"dczwhJI1l8Kl","executionInfo":{"status":"ok","timestamp":1691987760893,"user_tz":-540,"elapsed":458,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["# Basic settings\n","torch.manual_seed(470)\n","torch.cuda.manual_seed(470)\n","\n","#!pip install easydict\n","from easydict import EasyDict as edict\n","\n","args = edict()\n","args.batch_size = 32\n","args.nlayers = 2\n","args.ninp = 256\n","args.nhid = 256 #512\n","\n","\n","args.clip = 1\n","args.lr_lstm = 0.001\n","args.dropout = 0.2\n","args.nhid_attn = 256\n","args.epochs = 20\n","\n","##### Transformer\n","args.nhid_tran = 256\n","args.nhead = 8\n","args.nlayers_transformer = 6\n","args.attn_pdrop = 0.1\n","args.resid_pdrop = 0.1\n","args.embd_pdrop = 0.1\n","args.nff = 4 * args.nhid_tran\n","\n","\n","args.lr_transformer = 0.0001 #1.0\n","args.betas = (0.9, 0.98)\n","\n","args.gpu = True\n","\n","\n","device = 'cuda:0' if torch.cuda.is_available() and args.gpu else 'cpu'\n","# Create directory name.\n","result_dir = Path(root) / 'results'\n","result_dir.mkdir(parents=True, exist_ok=True)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQZvsEeDmeZt"},"source":["---\n","# Utility functions\n"]},{"cell_type":"code","metadata":{"id":"LUOvr2A_mf4Q","executionInfo":{"status":"ok","timestamp":1691987763042,"user_tz":-540,"elapsed":2,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["def word_ids_to_sentence(id_tensor, vocab, join=' '):\n","    \"\"\"Converts a sequence of word ids to a sentence\"\"\"\n","    if isinstance(id_tensor, torch.LongTensor):\n","        ids = id_tensor.transpose(0, 1).contiguous().view(-1)\n","    elif isinstance(id_tensor, np.ndarray):\n","        ids = id_tensor.transpose().reshape(-1)\n","    batch = [vocab.itos[ind] for ind in ids] # denumericalize\n","    if join is None:\n","        return batch\n","    else:\n","        return join.join(batch)\n","\n","# Extracts bias and non-bias parameters from a model.\n","def get_parameters(model, bias=False):\n","    for m in model.modules():\n","        if isinstance(m, nn.Linear):\n","            if bias:\n","                yield m.bias\n","            else:\n","                yield m.weight\n","        else:\n","            if not bias:\n","                yield m.parameters()\n","\n","def run_epoch(epoch, model, optimizer, is_train=True, data_iter=None):\n","    total_loss = 0\n","    n_correct = 0\n","    n_total = 0\n","    if data_iter is None:\n","        data_iter = train_iter if is_train else valid_iter\n","    if is_train:\n","        model.train()\n","    else:\n","        model.eval()\n","    for batch in data_iter:\n","        x, y, length = sort_batch(batch.src.to(device), batch.trg.to(device))\n","        target = y[1:]\n","        if isinstance(model, Transformer):\n","            x, y = x.transpose(0, 1), y.transpose(0, 1)\n","            target = target.transpose(0, 1) #y[:, 1:]\n","        pred = model(x, y, length)\n","        loss = criterion(pred.reshape(-1, trg_ntoken), target.reshape(-1))\n","        n_targets = (target != pad_id).long().sum().item()\n","        n_total += n_targets\n","        n_correct += (pred.argmax(-1) == target)[target != pad_id].long().sum().item()\n","        if is_train:\n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n","            optimizer.step()\n","\n","\n","        total_loss += loss.item() * n_targets\n","    total_loss /= n_total\n","    print(\"Epoch\", epoch, 'Train' if is_train else 'Valid',\n","          \"Loss\", np.mean(total_loss),\n","          \"Acc\", n_correct / n_total,\n","          \"PPL\", np.exp(total_loss))\n","    return total_loss\n","\n","def word_ids_to_sentence_(ids, vocab):\n","    sentence = []\n","    for ind in ids:\n","        if ind == eos_id:\n","            break\n","        sentence.append(vocab.itos[ind])\n","    return sentence\n","\n","def run_translation(model, data_iter, max_len=100, mode='best'):\n","    with torch.no_grad():\n","        model.eval()\n","        load_model(model, mode)\n","        src_list = []\n","        gt_list = []\n","        pred_list = []\n","        for batch in data_iter:\n","            x, y, length = sort_batch(batch.src.to(device), batch.trg.to(device))\n","            target = y[1:]\n","            if isinstance(model, Transformer):\n","                x, y = x.transpose(0, 1), y.transpose(0, 1)\n","                target = target.transpose(0, 1)\n","            pred = model(x, y, length, max_len=max_len, teacher_forcing=False)\n","            pred_token = pred.argmax(-1)\n","            if not isinstance(model, Transformer):\n","                pred_token = pred_token.transpose(0, 1).cpu().numpy()\n","                y = y.transpose(0, 1).cpu().numpy()\n","                x = x.transpose(0, 1).cpu().numpy()\n","            # pred_token : batch_size x max_len\n","            for x_, y_, pred_ in zip(x, y, pred_token):\n","                src_list.append(word_ids_to_sentence_(x_[1:], SRC.vocab))\n","                gt_list.append([word_ids_to_sentence_(y_[1:], TRG.vocab)])\n","                pred_list.append(word_ids_to_sentence_(pred_, TRG.vocab))\n","\n","        for i in range(5):\n","            print(f\"--------- Translation Example {i+1} ---------\")\n","            print(\"SRC :\", ' '.join(src_list[i]))\n","            print(\"TRG :\", ' '.join(gt_list[i][0]))\n","            print(\"PRED:\", ' '.join(pred_list[i]))\n","        print()\n","        print(\"BLEU:\", bleu_score(pred_list, gt_list))\n","\n","\n","\n","def save_model(model, mode=\"last\"):\n","    torch.save(model.state_dict(),  result_dir / f'{type(model).__name__}_{mode}.ckpt')\n","\n","def load_model(model, mode=\"last\"):\n","    if os.path.exists(result_dir / f'{type(model).__name__}_{mode}.ckpt'):\n","        model.load_state_dict(torch.load(result_dir / f'{type(model).__name__}_{mode}.ckpt'))\n","\n","def sort_batch(X, y, lengths=None):\n","    if lengths is None:\n","        lengths = (X != pad_id_src).long().sum(0)\n","    lengths, indx = lengths.sort(dim=0, descending=True)\n","    X = torch.index_select(X, 1, indx)\n","    y = torch.index_select(y, 1, indx)\n","    return X, y, lengths\n","\n","def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.uniform_(param.data, -0.08, 0.08)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Download Multi30k Dataset"],"metadata":{"id":"d09I8_00J2HM"}},{"cell_type":"code","source":["!wget -P .data/multi30k/ https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\n","!wget -P .data/multi30k/ https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\n","!wget -P .data/multi30k/ https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt_task1_test2016.tar.gz\n","\n","!tar -xzf .data/multi30k/training.tar.gz\n","!tar -xzf .data/multi30k/validation.tar.gz\n","!tar -xzf .data/multi30k/mmt_task1_test2016.tar.gz\n","!mv train.de train.en val.de val.en test2016.de test2016.en .data/multi30k/"],"metadata":{"id":"8IG1bC9HJ1hQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691987767371,"user_tz":-540,"elapsed":1091,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"c2093611-1c15-4d9a-c1cd-ef0204629a74"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-08-14 04:36:06--  https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1207136 (1.2M) [application/octet-stream]\n","Saving to: ‘.data/multi30k/training.tar.gz’\n","\n","\rtraining.tar.gz       0%[                    ]       0  --.-KB/s               \rtraining.tar.gz     100%[===================>]   1.15M  --.-KB/s    in 0.007s  \n","\n","2023-08-14 04:36:06 (162 MB/s) - ‘.data/multi30k/training.tar.gz’ saved [1207136/1207136]\n","\n","--2023-08-14 04:36:06--  https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 46329 (45K) [application/octet-stream]\n","Saving to: ‘.data/multi30k/validation.tar.gz’\n","\n","validation.tar.gz   100%[===================>]  45.24K  --.-KB/s    in 0.001s  \n","\n","2023-08-14 04:36:06 (45.4 MB/s) - ‘.data/multi30k/validation.tar.gz’ saved [46329/46329]\n","\n","--2023-08-14 04:36:06--  https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt_task1_test2016.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 66154 (65K) [application/octet-stream]\n","Saving to: ‘.data/multi30k/mmt_task1_test2016.tar.gz’\n","\n","mmt_task1_test2016. 100%[===================>]  64.60K  --.-KB/s    in 0.001s  \n","\n","2023-08-14 04:36:06 (74.4 MB/s) - ‘.data/multi30k/mmt_task1_test2016.tar.gz’ saved [66154/66154]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"r7WMaIEVmoub"},"source":["---\n","# Define `DataLoader` for training & validation set\n"]},{"cell_type":"code","source":["!git clone"],"metadata":{"id":"TR4OVn9mI78J"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"deEP6JnaywMV","executionInfo":{"status":"ok","timestamp":1691987784836,"user_tz":-540,"elapsed":8205,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["SRC = Field(tokenize = \"spacy\",\n","            tokenizer_language=\"de_core_news_sm\",\n","            init_token = '<sos>',\n","            eos_token = '<eos>',\n","            lower = True)\n","\n","TRG = Field(tokenize = \"spacy\",\n","            tokenizer_language=\"en_core_web_sm\",\n","            init_token = '<sos>',\n","            eos_token = '<eos>',\n","            lower = True)\n","\n","train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n","                                                    fields = (SRC, TRG))\n","SRC.build_vocab(train_data, min_freq = 2)\n","TRG.build_vocab(train_data, min_freq = 2)\n","\n","src_ntoken = len(SRC.vocab.stoi)\n","trg_ntoken = len(TRG.vocab.stoi)\n","\n","train_iter, valid_iter, test_iter = BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = args.batch_size,\n","    device = device)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"nSAnejfCywMZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691987795798,"user_tz":-540,"elapsed":8427,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"8ce6d195-f590-4c7c-bd17-77753597e712"},"source":["pad_id_trg = TRG.vocab.stoi[TRG.pad_token]\n","pad_id_src = SRC.vocab.stoi[SRC.pad_token]\n","pad_id = pad_id_src\n","eos_id = TRG.vocab.stoi[TRG.eos_token]\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n","\n","for batch in train_iter:\n","    src, trg, length_src = sort_batch(batch.src, batch.trg)\n","    print(length_src)\n","    print(src, src.shape)\n","    print(trg, trg.shape)\n","    break\n","\n","print(\"##### EXAMPLE #####\")\n","print(\"SRC: \", word_ids_to_sentence(src[:, 1:2].long().cpu(), SRC.vocab))\n","print(\"TRG: \", word_ids_to_sentence(trg[:, 1:2].long().cpu(), TRG.vocab))\n","\n","print(\"SRC vocab size\", len(SRC.vocab.stoi))\n","print(\"TRG vocab size\", len(TRG.vocab.stoi))\n","print(\"Vocab\", list(SRC.vocab.stoi.items())[:10])"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([27, 21, 20, 18, 17, 17, 17, 16, 16, 16, 15, 15, 15, 15, 15, 14, 14, 14,\n","        14, 13, 11, 11, 11, 10, 10, 10, 10, 10,  9,  9,  9,  8],\n","       device='cuda:0')\n","tensor([[   2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","            2,    2,    2,    2,    2,    2,    2,    2],\n","        [   5,    5,   18,    0,    5,    5,    8,    5,    5,    5,    5,   18,\n","           18,    5,   18,   76,  981,    5,    5,  492,   18,   18,   18,    8,\n","          490,    5,    5,    5,   18,    5,    8,    8],\n","        [  13,  417, 3342,  972,   13,   13,  165,   13,  329,   13,   13,   30,\n","           30,  177,   30, 1540,   11,  725,  272,   18,  954,   30,  103, 1423,\n","         1807,   70,   13,   25,  121,   26,    0,   16],\n","        [   7,    0, 5976, 1227,    7,   11,   68,   62,  114,  895,   62,   21,\n","           11,   25,   57,   41, 2338,    7,   13,   65, 1104,    0,   65,  204,\n","           19,   26,   11,   29,   57,   55,    0,  404],\n","        [ 206,  682, 1008,   42,    6,   14,    5,   11,   32,  109,    5, 2266,\n","            0,    7,    0,    7,   12,    6,    7,   10,    8,   10,   57,    7,\n","          567,   38,  355,   12,  131,  583,   12,   17],\n","        [  40,   85,   14,   17,   71,  175,  148,  197,   93, 5608,  259,   44,\n","           52,    6,    9, 1070,  172, 4017,    6,   15, 1038,  258, 1063,   14,\n","            7,   12,  265,    6,  133,   14,   15, 2062],\n","        [  10,    8,  112,    0,   40,  375,   22,  787,  139,  753,    9,    0,\n","           12,  341,   35,   10,  317,   95,   51,   32,   64,   85,   12,    0,\n","           33,   14,   38,  356,   92,  562,  136,    4],\n","        [  46,   26,  419, 7475,   31,   60,  172,   12, 6949,    0,   35,    9,\n","           14,  475,    5,    8,  554,   17, 1085,  141,   39,    5,   14, 2149,\n","          629,  439,  816,  214,    4,    4,    4,    3],\n","        [ 198,   16,  165,    9,   47,   21, 2405,   24,   12,   12,  145,   39,\n","          340,    9, 2093,   67,   21,    0,   40,   42, 6266,  148, 1571,    4,\n","            4,    4,    4,    4,    3,    3,    3,    1],\n","        [   9,   11,    7,   17,   14,   18,   10,  649,   19,    6,    8, 2382,\n","           34, 2410,   12,   12,    6,  109, 1971,    8,    4,    4,    4,    3,\n","            3,    3,    3,    3,    1,    1,    1,    1],\n","        [  15,    6,    6,  930,   16,    0,   37,   12,  112,   78,  243,   20,\n","           59,   58,    6,    6,  141, 3069,  149,  247,    3,    3,    3,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  12,  112, 1074,    0,    9,    7,  147,    6,  153, 3227,  478,   63,\n","            6,   19,  142,   87,  398,   21,  143,    4,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  33,   80,    9,   11,   17,    0,  125,   50,   32,   56,   61,  156,\n","            0, 2136,    0,    4,    4,    4,    4,    3,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [1131,    9,   35,    0,  129, 2686,  829,  259,  975,  917,    4,    4,\n","            4,    4,    4,    3,    3,    3,    3,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  14,   15,    8,    0,   38,  117,  420,    4,    4,    4,    3,    3,\n","            3,    3,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [ 197,  126,  101, 3763,    4,    4,    4,    3,    3,    3,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [ 363,   24,  165,    4,    3,    3,    3,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [ 146,  107,  434,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  10,  895,    4,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [   7,    4,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  15,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  94,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  81,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [4643,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  37,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [   4,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [   3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:0') torch.Size([27, 32])\n","tensor([[   2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","            2,    2,    2,    2,    2,    2,    2,    2],\n","        [   9,   21,   16, 1192,    4,    4,  120,    4,    4,    4,    4,   16,\n","           16,   24,   16,  113,  494,    4,   21,  860,   16,   16,   16,    4,\n","          932,    4,    4,    4,   16,    4,    4,    4],\n","        [   6,  297, 1332,  989,    9,    9,  165,    9,   59,    9,    9,   30,\n","           30,   33,   30,   19,   13, 1206,  145,   16, 5128,   30,   70,  183,\n","          230,   24,    9,   33,  112,   34,  251,   14],\n","        [  29, 4387, 3599, 1228,    6,  151,    4,  971,   26,   10,   78,   17,\n","            6,    6,  128,   17, 2322,    6,    9,   63,   17,   17,   63,  781,\n","            4,   34,   13,   10,   37,   20,    9,   56],\n","        [  23,    4,   17, 1675,    4,   21,  134,    4,   35, 1394,    4, 2644,\n","          898,    4,    0,   41, 1574,    4,    6,   11,  656,  292, 1086,  269,\n","          438,  137,  549,   36,   68,    7, 1702,   75],\n","        [  11,   24, 2655,    7,   26,   86,    6,   31,  136,   40,  295,    4,\n","          279,  713,   28,   28,    6,  755,    4,   35,    4,  139,   37,    6,\n","            6,    8,   23,    8,  129,  723,  237,   20],\n","        [  26,   14,    4, 2330,   23,  265,    7,  295,   27,   28,   28, 1522,\n","          100,  306,    4,   22,    4, 1411,   25,   17,  928, 1711,    8,    4,\n","            7,    4,   10,    4,   57,   12,    8,    4],\n","        [ 147,   13,   70, 3083,   91,  125,  704,   13, 4276,  321,   22,  180,\n","           49,  300,  947,  826,  164,  173,  314,   79,   83,   11,    4,    0,\n","          488,  308,   37,  331,    5,    4,  149,  428],\n","        [  10,    4,   15,    0,   71,  232,   28,   27,    8,   27,    4,   32,\n","            4, 3563,  107,   15,    5,   50,  109,   60,    7,  249,  861,  379,\n","            5,    5,  213,  479,    3, 3669,    5,    5],\n","        [  56,   70,  233,   18,   18,   16,   45,  829,    4, 1853,   26, 4738,\n","          597,   60,    8,   28,    3, 1824,   10,    4,  381,   54,  308,    5,\n","            3,    3,    5,    5,    1,   11,    3,    3],\n","        [  20,   34,  120,  209,    4, 2440,   44,    6,   70,    8,  231,    6,\n","           12,    4,    8,   46,    1,   58,    0,   85,    5,    4,    5,    3,\n","            1,    1,    3,    3,    1,  416,    1,    1],\n","        [  27, 1317,    6, 5805,   14, 1176,  352,   27,   61,    4,    5,    7,\n","         1160,  248,    4,   10,    1,  244,   27,   12,    3,  134,    3,    1,\n","            1,    1,    1,    1,    1,    5,    1,    1],\n","        [2071,  199,    4,   18,   37, 1743,    5,  672,   35,   59,    3,   47,\n","            8,  268,   84,   78,    1,  673,  172,   96,    1,    5,    1,    1,\n","            1,    1,    1,    1,    1,    3,    1,    1],\n","        [   8,    7, 1070, 3201,    7,  925,    3,    5,    5,  307,    1,    5,\n","            4,    5,    5,    4,    1,   49,    5,    5,    1,    3,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  46,   94,   15, 3810,  126,    5,    1,    3,    3, 1273,    1,    3,\n","          267,    3,    3,   99,    1,    5,    3,    3,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [ 139,    5,   28, 1088,    5,    3,    1,    1,    1,  532,    1,    1,\n","           39,    1,    1,    5,    1,    3,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  28,    3,   82,    5,    3,    1,    1,    1,    1,    5,    1,    1,\n","            5,    1,    1,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  45,    1,  120,    3,    1,    1,    1,    1,    1,    3,    1,    1,\n","            3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [ 146,    1,  229,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [   6,    1,    5,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  27,    1,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [  72,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [ 139,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [   5,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1],\n","        [   3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:0') torch.Size([25, 32])\n","##### EXAMPLE #####\n","SRC:  <sos> ein schirm <unk> schatten für eine junge frau mit einem kleinen jungen , der unter dem tisch hockt . <eos> <pad> <pad> <pad> <pad> <pad> <pad>\n","TRG:  <sos> an umbrella shading a young woman with a small boy crouching under the table . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n","SRC vocab size 7872\n","TRG vocab size 5897\n","Vocab [('<unk>', 0), ('<pad>', 1), ('<sos>', 2), ('<eos>', 3), ('.', 4), ('ein', 5), ('einem', 6), ('in', 7), ('eine', 8), (',', 9)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"OVy7Dc_rmw2A"},"source":["---\n","# Define networks\n","\n","You should implement the `forward()` method of the given classes. Some classes are provided with the `forward()` method as well; you don't have to change anything in this case. However, **you are not allowed to modify the `__init__` method of all classes.**"]},{"cell_type":"markdown","metadata":{"id":"9yg7ZEwvO9_9"},"source":["## P1. Implement LSTM"]},{"cell_type":"markdown","metadata":{"id":"5YK28D7EO_Fd"},"source":["### (a)  LSTMCell [(illustration)](https://docs.google.com/drawings/d/1ICw_GxDMxkSS5g7D1w6gXDkLm3NAok1otmPcwYzLPEg/edit?usp=sharing)\n","- LSTMCell is a single unit constructing LSTM. It gets current input(`x`) and previous state (which is composed of hidden state `hx` and cell state `cx`) as inputs and returns the state for the next time step (`hy` and `cy`). There are four switch variables to handle information flows through time. Implement forward function with those four switch variables following the illustration."]},{"cell_type":"code","metadata":{"id":"AT0CJePPPS_E","executionInfo":{"status":"ok","timestamp":1691994799558,"user_tz":-540,"elapsed":747,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class LSTMCell(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(LSTMCell, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.linear_input = nn.Linear(input_size, 4 * hidden_size)\n","        self.linear_hidden = nn.Linear(hidden_size, 4 * hidden_size)\n","\n","    def forward(self, x, state):\n","        # type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\n","        hx, cx = state\n","        gates = self.linear_input(x) + self.linear_hidden(hx)\n","        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n","\n","        ingate = torch.sigmoid(ingate)\n","        forgetgate = torch.sigmoid(forgetgate)\n","        cellgate = torch.tanh(cellgate)\n","        outgate = torch.sigmoid(outgate)\n","\n","        cy = (forgetgate * cx) + (ingate * cellgate)\n","        hy = outgate * torch.tanh(cy)\n","\n","        return hy, (hy, cy)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IOd-XpyGO_qH"},"source":["### (b) LSTM [(illustration)](https://docs.google.com/drawings/d/1eiYyY9k6NELizHcRAsOS6jkEi_mISjfFlXntv8gaGZI/edit?usp=sharing)\n","- LSTMLayer is a single layer composed of sequential LSTMCells. While LSTMCell handles a single input, LSTMLayer gets a sequence as an input and processes it in an autoregressive manner. You don't need to implement LSTMLayer. It will be given.\n","- Using LSTMLayer, you should implement one full LSTM module by stacking multiple LSTMLayers. Note that `states` now contain multiple `state`s where each state becomes an initial state for a different level of LSTMLayers. Also, each output of an LSTMLayer is fed into the next layer of LSTMLayer as an input.\n","As a result, LSTM returns `output` tensor of size (L,B,nhid) and `output_states` consists of output states from different levels of LSTMLayers, which is a type of List(Tensor, Tensor, ..., Tensor) and each Tensor has a size of (L,B,nhid). Here L,B,nhid are a maximum length of sentences within a batch (equal to `x.size(0)`), batch size, and dimension size of hidden states, respectively. Implement the forward function following the given illustration."]},{"cell_type":"code","metadata":{"id":"Wjf1QmRAPYdd","executionInfo":{"status":"ok","timestamp":1691994801657,"user_tz":-540,"elapsed":2,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class LSTMLayer(nn.Module):\n","    def __init__(self,*cell_args):\n","        super(LSTMLayer, self).__init__()\n","        self.cell = LSTMCell(*cell_args)\n","\n","    def forward(self, x, state, length_x=None):\n","        # DO NOT MODIFY\n","        # type: (Tensor, Tuple[Tensor, Tensor]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\n","        inputs = x.unbind(0)\n","        assert (length_x is None) or torch.all(length_x == length_x.sort(descending=True)[0])\n","        outputs = []\n","        out_hidden_state = []\n","        out_cell_state = []\n","        for i in range(len(inputs)):\n","            out, state = self.cell(inputs[i] , state)\n","            outputs += [out]\n","            if length_x is not None:\n","                if torch.any(i+1 == length_x):\n","                    out_hidden_state = [state[0][i+1==length_x]] + out_hidden_state\n","                    out_cell_state = [state[1][i+1==length_x]] + out_cell_state\n","        if length_x is not None:\n","            state = (torch.cat(out_hidden_state, dim=0), torch.cat(out_cell_state, dim=0))\n","        return torch.stack(outputs), state\n","\n","\n","class LSTM(nn.Module):\n","    def __init__(self, ninp, nhid, num_layers, dropout):\n","        super(LSTM, self).__init__()\n","        self.layers = []\n","        self.dropout = nn.Dropout(dropout)\n","        for i in range(num_layers):\n","            if i == 0:\n","                self.layers.append(LSTMLayer(ninp, nhid))\n","            else:\n","                self.layers.append(LSTMLayer(nhid, nhid))\n","        self.layers = nn.ModuleList(self.layers)\n","\n","    def forward(self, x, states, length_x=None):\n","        # TO DO\n","        # WRITE YOUR CODE HERE\n","        output_states = []\n","        output = x\n","        i = 0\n","        for rnn_layer, state in zip(self.layers, states):\n","            if i > 0:\n","                output = self.dropout(output)\n","            output, out_state = rnn_layer(output, state, length_x=length_x)\n","            output_states.append(out_state)\n","            i += 1\n","        return output, output_states"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qXJsTGg3O-m4"},"source":["### (c)  Implement LSTMEncoder[(illustration)](https://docs.google.com/drawings/d/1wt5JhHtsx5b28KEem-_RX0FdeDmtUzSm0SJDypoCmtM/edit?usp=sharing)\n","LSTMEncoder encodes a sequence of tokens into the context vector. It first embeds a tokenized sequence using the embedding layer followed by dropout layer, and then LSTM computes `output` and `context_vector`. Implement the forward function following the given illustration.\n"]},{"cell_type":"code","metadata":{"id":"1b6J1a39PY4P","executionInfo":{"status":"ok","timestamp":1691994803845,"user_tz":-540,"elapsed":478,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class LSTMEncoder(nn.Module):\n","    def __init__(self):\n","        super(LSTMEncoder, self).__init__()\n","        ninp = args.ninp\n","        nhid = args.nhid\n","        nlayers = args.nlayers\n","        dropout = args.dropout\n","        self.embed = nn.Embedding(src_ntoken, ninp, padding_idx=pad_id)\n","        self.dropout = nn.Dropout(dropout)\n","        self.lstm = LSTM(ninp, nhid, nlayers, dropout)\n","\n","    def forward(self, x, states, length_x=None):\n","        # TO DO\n","        # WRITE YOUR CODE HERE\n","        x = self.dropout(self.embed(x))\n","        output, context_vector = self.lstm(x, states, length_x=length_x)\n","        return output, context_vector"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrFAmuJRO9eG"},"source":["### (d)  Implement LSTMDecoder[(illustration)](https://docs.google.com/drawings/d/151_NavPXUYtxbEDXBPpeMZnn0HlcZ-UVcIbSZFPU2o4/edit?usp=sharing)\n","LSTMDecoder gets a single token as an input to predict the next token. Similar to LSTMEncoder, it first embeds a given input (usually a predicted token from last time step) using embedding layer followed by dropout layer, and then LSTM computes `output` and `output_states`. Implement the forward function following the given illustration."]},{"cell_type":"code","metadata":{"id":"k2vRxaa3PZom","executionInfo":{"status":"ok","timestamp":1691994805933,"user_tz":-540,"elapsed":2,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class LSTMDecoder(nn.Module):\n","    def __init__(self):\n","        super(LSTMDecoder, self).__init__()\n","        self.embed = nn.Embedding(trg_ntoken, args.ninp, padding_idx=pad_id)\n","        self.lstm = LSTM(args.ninp, args.nhid, args.nlayers, args.dropout)\n","        self.fc_out = nn.Linear(args.nhid, trg_ntoken)\n","        self.dropout = nn.Dropout(args.dropout)\n","        self.fc_out.weight = self.embed.weight\n","\n","    def forward(self, x, states):\n","        # TO DO\n","        # WRITE YOUR CODE HERE\n","        x = self.dropout(self.embed(x))\n","        output, output_states = self.lstm(x, states)\n","        output = self.fc_out(output)\n","        return output, output_states"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QjbbVJcbO9I3"},"source":["### (e)  Implement LSTMSeq2Seq[(illustration)](https://docs.google.com/drawings/d/1xWxCE44_IaQhtxEXSnvA5fzdBjylj3_Maj9B02glMqs/edit?usp=sharing)\n","LSTMSeq2Seq is a complete model for neural machine translation. It starts with LSTMEncoder encoding a given tokenized sequence into the context vector. LSMTDecoder then decodes the context vector step by step. As mentioned in the description for LSTMDecoder, each input for the decoder is a token predicted by the previous decoder. In the training stage, however, one noisy prediction from the previous decoder can mess up all of the following predictions so teacher forcing is used in the training stage. Teacher forcing allows LSTMdecoder to always ground-truth token as an input instead of predicted one from the previous step. Therefore, implement the forward function to use the ground-truth label for the input for LSTMDecoder if `teacher_focing` is True (it's the case for training stage), and use the predicted token from last time step otherwise (case for inference). Also, note that all of the sentences start with <sos> token so the first input token to LSTMDecoder should be always `<sos>`. Implement the forward function following the given illustration."]},{"cell_type":"code","metadata":{"id":"NLC1mpEFm05u","executionInfo":{"status":"ok","timestamp":1691994906229,"user_tz":-540,"elapsed":639,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class LSTMSeq2Seq(nn.Module):\n","    def __init__(self):\n","        super(LSTMSeq2Seq, self).__init__()\n","        self.encoder = LSTMEncoder()\n","        self.decoder = LSTMDecoder()\n","\n","    def _get_init_states(self, x):\n","        init_states = [\n","            (torch.zeros((x.size(1), args.nhid)).to(x.device),\n","            torch.zeros((x.size(1), args.nhid)).to(x.device))\n","            for _ in range(args.nlayers)\n","        ]\n","        return init_states\n","\n","    def forward(self, x, y, length, max_len=None, teacher_forcing=True):\n","        # TO DO\n","        # WRITE YOUR CODE HERE\n","        init_states = self._get_init_states(x)\n","        _, output_states = self.encoder(x, init_states, length)\n","\n","        trg_len = y.size(0) if max_len is None else max_len\n","        dec_outputs = []\n","        for i in range(trg_len-1):\n","          if teacher_forcing or i == 0:\n","            dec_input = y[i:1+1]\n","          else:\n","            dec_input = dec_output.argmax(-1)\n","          dec_output, output_states = self.decoder(dec_input, output_states)\n","          dec_outputs.append(dec_output)\n","        return torch.cat(dec_outputs, dim=0)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TG_fK-sWjLT5"},"source":["\n","## P2. Implement Transformer\n","\n","**This section has no dependency on the two preceding models; you can implement the Transformer first if you want to.**"]},{"cell_type":"markdown","metadata":{"id":"w4tGUyntXKXk"},"source":["### (a) Implement MaskedMultiheadAttention [(Illustration)](https://docs.google.com/drawings/d/1kCsVW-61xHT-riSDxGzF8VBRo2CpqrE0ngG7H21wirs/edit?usp=sharing)\n","In this module, you will implement a single layer of multi-head attention, which will be the key building block of the Transformer model. Each query, key, value input will first pass through a feed-forward network, then scaled dot-product attention is performed. Additionally, there's an optional mask layer inside the scaled dot-product attention applied only in the decoder stage of the Transformer, to prevent the model from being able to see future inputs. Implement the forward function following the given illustration."]},{"cell_type":"code","metadata":{"id":"OFeZAJNCPEll","executionInfo":{"status":"ok","timestamp":1691994911690,"user_tz":-540,"elapsed":557,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["MAX_LEN = 100\n","class MaskedMultiheadAttention(nn.Module):\n","    \"\"\"\n","    A vanilla multi-head masked attention layer with a projection at the end.\n","    \"\"\"\n","    def __init__(self, mask=False):\n","        super(MaskedMultiheadAttention, self).__init__()\n","        assert args.nhid_tran % args.nhead == 0\n","        # mask : whether to use\n","        # key, query, value projections for all heads\n","        self.key = nn.Linear(args.nhid_tran, args.nhid_tran)\n","        self.query = nn.Linear(args.nhid_tran, args.nhid_tran)\n","        self.value = nn.Linear(args.nhid_tran, args.nhid_tran)\n","        # regularization\n","        self.attn_drop = nn.Dropout(args.attn_pdrop)\n","        # output projection\n","        self.proj = nn.Linear(args.nhid_tran, args.nhid_tran)\n","        # causal mask to ensure that attention is only applied to the left in the input sequence\n","        if mask:\n","            self.register_buffer(\"mask\", torch.tril(torch.ones(MAX_LEN, MAX_LEN)))\n","        self.nhead = args.nhead\n","        self.d_k = args.nhid_tran // args.nhead\n","\n","    def forward(self, q, k, v, mask=None):\n","        # WRITE YOUR CODE HERE\n","        B, T_q, C = q.shape\n","        _, T, _ = k.shape\n","\n","        q = self.query(q).view(B, T_q, self.nhead, self.d_k).transpose(1, 2)\n","        k = self.key(k).view(B, T, self.nhead, self.d_k).transpose(1, 2)\n","        v = self.value(v).view(B, T, self.nhead, self.d_k).transpose(1, 2)\n","\n","        att = (q @ k.transpose(-2, -1)) / (C ** 0.5)\n","\n","        if hasattr(self, 'mask'):\n","          att[:, :, self.mask[:T_q, :T] == 0] = float('-inf')\n","        if mask is not None:\n","          assert len(mask.shape) == 2\n","          att = att.transpose(0, 2)\n","          att[:, :, mask == 0] = float('-inf')\n","          att = att.transpose(0, 2)\n","\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_drop(att)\n","        y = att @ v\n","        y = y.transpose(1, 2).contiguous().view(B, T_q, C)\n","\n","        y = self.proj(y)\n","\n","        return y"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pWn3GenhPG1G"},"source":["\n","### (b) Implement TransformerEncLayer [(Illustration)](https://docs.google.com/drawings/d/1DSJmF8z0g79J0EZCY8WyTDR0pxUmsmqNEVU9jxYrrsY/edit?usp=sharing)\n","This module is a single layer of the Transformer encoder, containing a layer of masked multi-head attention and a feed-forward network with dropout and skip connection. Both attention and feed-forward layer have skip connections and are preceded by LayerNorm. You will stack this layer multiple times to create the full version of the encoder. Since attention is performed in a self-attention manner, you will pass the same values to query, key, and value inputs of the MaskedSelfAttention module.\n"]},{"cell_type":"code","metadata":{"id":"1RcLE8QKPPfJ","executionInfo":{"status":"ok","timestamp":1691994916450,"user_tz":-540,"elapsed":562,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class TransformerEncLayer(nn.Module):\n","    def __init__(self):\n","        super(TransformerEncLayer, self).__init__()\n","        self.ln1 = nn.LayerNorm(args.nhid_tran)\n","        self.ln2 = nn.LayerNorm(args.nhid_tran)\n","        self.attn = MaskedMultiheadAttention()\n","        self.dropout1 = nn.Dropout(args.resid_pdrop)\n","        self.dropout2 = nn.Dropout(args.resid_pdrop)\n","        self.ff = nn.Sequential(\n","            nn.Linear(args.nhid_tran, args.nff),\n","            nn.ReLU(),\n","            nn.Linear(args.nff, args.nhid_tran)\n","        )\n","\n","    def forward(self, x, mask=None):\n","        # WRITE YOUR CODE HERE\n","        x = self.ln1(x)\n","        o = self.dropout1(self.attn(x, x, x, mask))\n","        x = x + o\n","\n","        x = self.ln2(x)\n","        o = self.dropout2(self.ff(x))\n","        x = x + o\n","\n","        return x"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oKz8TOrEPVu4"},"source":["### (c) Implement TransformerDecLayer [(Illustration)](https://docs.google.com/drawings/d/1qNP7ibDTWCRhXJdejtO7jRkvj5RrPN90ORwuK-ANT-4/edit?usp=sharing)\n","This module is a single layer of the Transformer decoder. The module contains two masked multi-head attentions and a feed-forward network, all with a skip connection and a preceding LayerNorm. The first attention is identical to the encoder's attention. However, the second attention is a cross-attention: that is, the key and value inputs of this layer would be the encoded words from the **source** sentence, given as `enc_o`.\n","\n"]},{"cell_type":"code","metadata":{"id":"Bnp9dhwsPXjB","executionInfo":{"status":"ok","timestamp":1691994919069,"user_tz":-540,"elapsed":484,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class TransformerDecLayer(nn.Module):\n","    def __init__(self):\n","        super(TransformerDecLayer, self).__init__()\n","        self.ln1 = nn.LayerNorm(args.nhid_tran)\n","        self.ln2 = nn.LayerNorm(args.nhid_tran)\n","        self.ln3 = nn.LayerNorm(args.nhid_tran)\n","        self.dropout1 = nn.Dropout(args.resid_pdrop)\n","        self.dropout2 = nn.Dropout(args.resid_pdrop)\n","        self.dropout3 = nn.Dropout(args.resid_pdrop)\n","        self.attn1 = MaskedMultiheadAttention(mask=True) # self-attention\n","        self.attn2 = MaskedMultiheadAttention() # tgt to src attention\n","        self.ff = nn.Sequential(\n","            nn.Linear(args.nhid_tran, args.nff),\n","            nn.ReLU(),\n","            nn.Linear(args.nff, args.nhid_tran)\n","        )\n","\n","    def forward(self, x, enc_o, enc_mask=None):\n","        # WRITE YOUR CODE HERE\n","        x = self.ln1(x)\n","        o = self.dropout1(self.attn1(x, x, x))\n","        x = x + o\n","\n","        x = self.ln2(x)\n","        o = self.dropout2(self.attn2(x, enc_o, enc_o, enc_mask))\n","        x = x + o\n","\n","        x = self.ln3(x)\n","        o = self.dropout3(self.ff(x))\n","        x = x + o\n","\n","        return x"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NO7tjDWvPbx3"},"source":["### (d) Implement TransformerEncoder [(Illustration)](https://docs.google.com/drawings/d/1WtbU0xcaAVWsVegSwO0AzZBfk9NNDltTY9P-GiImVqg/edit?usp=sharing)\n","In this module, you will first tokenize the input word, apply positional encoding (Refer to `PositionalEncoding` class that we've implemented for you), then pass through multiple layers of TransformerEncLayer, and conclude with a LayerNorm.\n"]},{"cell_type":"code","metadata":{"id":"EjdoK0opPdEC","executionInfo":{"status":"ok","timestamp":1691994921969,"user_tz":-540,"elapsed":503,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, max_len=4096):\n","        super().__init__()\n","        dim = args.nhid_tran\n","        pos = np.arange(0, max_len)[:, None]\n","        i = np.arange(0, dim // 2)\n","        denom = 10000 ** (2 * i / dim)\n","\n","        pe = np.zeros([max_len, dim])\n","        pe[:, 0::2] = np.sin(pos / denom)\n","        pe[:, 1::2] = np.cos(pos / denom)\n","        pe = torch.from_numpy(pe).float()\n","\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        # DO NOT MODIFY\n","        return x + self.pe[:x.shape[1]]\n","\n","class TransformerEncoder(nn.Module):\n","\n","    def __init__(self):\n","        super(TransformerEncoder, self).__init__()\n","        # input embedding stem\n","        self.tok_emb = nn.Embedding(src_ntoken, args.nhid_tran)\n","        self.pos_enc = PositionalEncoding()\n","        self.dropout = nn.Dropout(args.embd_pdrop)\n","        # transformer\n","        self.transform = nn.ModuleList([TransformerEncLayer() for _ in range(args.nlayers_transformer)])\n","        # decoder head\n","        self.ln_f = nn.LayerNorm(args.nhid_tran)\n","\n","\n","    def forward(self, x, mask):\n","      x = self.dropout(self.pos_enc(self.tok_emb(x)))\n","\n","      for m in self.transform:\n","        x = m(x, mask)\n","      outputs = self.ln_f(x)\n","\n","      return outputs"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XkSdxiGJPgPm"},"source":["### (e) Implement TransformerDecoder [(Illustration)](https://docs.google.com/drawings/d/1cipGddhtugoqM31H6_5fswHSYCXPSiMrJ85GdhGfz4c/edit?usp=sharing)\n","What TransformerDecoder does is pretty much identical to TransformerEncoder. There are two differences: first is that you should use TransformerDecLayer instead of TransformerEncLayer (obviously!), the other difference is that there's an extra linear layer at the very end of the pipeline.\n"]},{"cell_type":"code","metadata":{"id":"Ft64IQHrPlCb","executionInfo":{"status":"ok","timestamp":1691994924914,"user_tz":-540,"elapsed":480,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class TransformerDecoder(nn.Module):\n","    def __init__(self):\n","        super(TransformerDecoder, self).__init__()\n","        self.tok_emb = nn.Embedding(trg_ntoken, args.nhid_tran)\n","        self.pos_enc = PositionalEncoding()\n","        self.dropout = nn.Dropout(args.embd_pdrop)\n","        self.transform = nn.ModuleList([TransformerDecLayer() for _ in range(args.nlayers_transformer)])\n","        self.ln_f = nn.LayerNorm(args.nhid_tran)\n","        self.lin_out = nn.Linear(args.nhid_tran, trg_ntoken)\n","        self.lin_out.weight = self.tok_emb.weight\n","\n","\n","    def forward(self, x, enc_o, enc_mask):\n","        # WRITE YOUR CODE HERE\n","        x = self.dropout(self.pos_enc(self.tok_emb(x)))\n","\n","        for m in self.transform:\n","          x = m(x, enc_o, enc_mask)\n","        x = self.ln_f(x)\n","\n","        logits /= args.nhid_tran ** 0.5 # Scaling logits. Do not modify this\n","        return logits"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7nxKg_RfPpz4"},"source":["### (f) Implement Transformer [(Illustration)](https://docs.google.com/drawings/d/18BeRA4Jl--rR5Txvyfr3nA5SA7ve8nESjZJSiD51ULw/edit?usp=sharing)\n","Finally, we combine everything to construct the full Transformer model. Begin by creating a mask according to `length_x` parameter, and pass the inputs through TransformerEncoder to obtain encoder output. Now if we're on training mode (`self.training == True`) or teacher forcing is enabled, then we run through the decoder exactly once to predict the very next word. Otherwise, we run through the decoder `max_len - 1` times to create a sequence of `max_len` tokens. The first token to feed the decoder is always the first token of `y`.\n"]},{"cell_type":"code","metadata":{"id":"EWsZrYEGywMi","executionInfo":{"status":"ok","timestamp":1691994927604,"user_tz":-540,"elapsed":500,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["class Transformer(nn.Module):\n","    def __init__(self):\n","        super(Transformer, self).__init__()\n","        self.encoder = TransformerEncoder()\n","        self.decoder = TransformerDecoder()\n","\n","    def forward(self, x, y, length_x, max_len=None, teacher_forcing=True):\n","        # WRITE YOUR CODE HERE\n","        max_len_src = x.size(1)\n","        if length_x is not None:\n","          enc_mask = length_x.view(-1, 1) > torch.arange(max_len_src).to(length_x.device)\n","        else:\n","          enc_mask = None\n","        enc_o = self.encoder(x, enc_mask)\n","        if self.training or teacher_forcing:\n","          return self.decoder(y[:, :-1], enc_o, enc_mask)\n","\n","        dec_input = y[:, :1]\n","        if max_len is None:\n","          max_len = y.shape[1]\n","        for t in range(1, max_len):\n","          dec_output = self.decoder(dec_input, enc_o, enc_mask)\n","          dec_input = torch.cat((dec_input, dec_output[:, -1:].argmax(-1)), dim=-1)\n","        return dec_output\n","\n"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iHQzs6ocPxtQ"},"source":["## Run Experiment\n","\n","You can run the experiment after you've finished at least one out of the three models. However, please **run every single cell above (even the cells you haven't implemented yet)** to run the function properly. We expect training a model for 20 epochs should take less than an hour."]},{"cell_type":"code","metadata":{"id":"YdxUX81cywMk","executionInfo":{"status":"ok","timestamp":1691994930016,"user_tz":-540,"elapsed":480,"user":{"displayName":"백삼기","userId":"07015587273030351036"}}},"source":["def run_experiment(model):\n","    criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=args.lr_lstm if not isinstance(model, Transformer) else args.lr_transformer)\n","\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n","            factor=0.25, patience=1, threshold=0.0001, threshold_mode='rel',\n","            cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n","\n","    best_val_loss = np.inf\n","    for epoch in tq.tqdm(range(args.epochs)):\n","        run_epoch(epoch, model, optimizer, is_train=True)\n","        with torch.no_grad():\n","            val_loss = run_epoch(epoch, model, None, is_train=False)\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            save_model(model, 'best')\n","        save_model(model)\n","        scheduler.step(val_loss)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UytcJfBv8b3Y"},"source":["## P4. Train and Validate models (15pts)\n","**About evaluation metrics**\n","\n","[PPL(Perplexity)](https://en.wikipedia.org/wiki/Perplexity) can be interpreted as \"how many words are considered as candidate output on every time step\". A lower perplexity means the model is more confident with its output.\n","\n","[BLEU(Bilingual Evaluation Understudy) Score](https://en.wikipedia.org/wiki/BLEU) is a general metric to measure the quality of machine translation output. It takes three elements into calculation:\n","- Precision: How accurate are each n-gram of the predicted sentence?\n","- Clipping: Calibrate the score when a word occurs multiple times in true/predicted sentence.\n","- Brevity penalty: The predicted and true sentence should have identical (or similar) length.\n","\n","A higher  BLEU score is considered a better quality translation.\n","\n","We will evaluate your performance based on each model's BLEU score, with ±0.02 error tolerance. The exact values are subject to change, don't worry too much if you missed the range by a small margin. The point for each model is **5pts**.\n","\n","**Expected BLEU Score**\n","- LSTMSeq2Seq: 0.245 ± 0.02\n","- Transformer: 0.358 ± 0.02"]},{"cell_type":"code","metadata":{"id":"-ByvNFinywMm","colab":{"base_uri":"https://localhost:8080/","height":438,"referenced_widgets":["61da974aadf445d484edb149399d5630","b71b202e24e34574aca8e007e6f982d4","4310c7c2f04d4c1497a6dbeb3ae83012","6234f5aaacd443b58fefb755a3743039","98be2c51e5794b31bc465fdd4621ab60","115b7682e73444e58522a755b4c65734","3e4eb9980cd941f882f9d6a0233bb96f","4f5743fff6b54497b02b75b612be6954","7b88373cd4bc4a5d9d842723a51dc5de","4535a8c99966498a89e78458342d1300","82c688532f8847d8a1ac9c1c77e4d8d6"]},"executionInfo":{"status":"error","timestamp":1691994935873,"user_tz":-540,"elapsed":3823,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"3c33a88b-2977-47e5-ffb0-5ca047a613a4"},"source":["lstm_model = LSTMSeq2Seq().to(device)\n","lstm_model.apply(init_weights)\n","run_experiment(lstm_model)\n","run_translation(lstm_model, test_iter, max_len=100)\n","print('')"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61da974aadf445d484edb149399d5630"}},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-acc9f0a5642e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrun_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-96c79728bccc>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-525c83a300eb>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(epoch, model, optimizer, is_train, data_iter)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#y[:, 1:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_ntoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mn_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpad_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-f1f4d0c4d3c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, length, max_len, teacher_forcing)\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m           \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m           \u001b[0mdec_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-e871d304e5f7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, states)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# WRITE YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-f28a9f2bf100>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, states, length_x)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0moutput_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-f28a9f2bf100>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, state, length_x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_cell_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"]}]},{"cell_type":"code","metadata":{"id":"UU65AMeUywMu","colab":{"base_uri":"https://localhost:8080/","height":402,"referenced_widgets":["8f2ad7ab85724407b69a7f9577d67896","d6a2fbeedc5c460da10b6946de0804f5","89e3f5f0cc4c496985310a79a45a247f","704ad48274614221b1a55bb129fad1a8","15cfce1b9a714942a6cf920099737f0f","d19ea6857bf242a3840d1eab56a5f84b","a144217eb62843268c42110179dfe8e6","67ef7a16c0d34be9a99137345ffc8cc4","f858beb308f74ef59e7e3719e73a6a2a","4a20eea636974000b9383e4392325816","595c1f4fd46c4a4bbe605e34423f165d"]},"executionInfo":{"status":"error","timestamp":1691994950183,"user_tz":-540,"elapsed":615,"user":{"displayName":"백삼기","userId":"07015587273030351036"}},"outputId":"92fd53d7-52ef-4ab7-cf21-46717ac6e05d"},"source":["transformer_model = Transformer().to(device)\n","run_experiment(transformer_model)\n","run_translation(transformer_model, test_iter, max_len=100)\n","print('')"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f2ad7ab85724407b69a7f9577d67896"}},"metadata":{}},{"output_type":"error","ename":"UnboundLocalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-d596748ea355>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrun_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-96c79728bccc>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-525c83a300eb>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(epoch, model, optimizer, is_train, data_iter)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#y[:, 1:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_ntoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mn_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpad_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-12cd121d9a79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, length_x, max_len, teacher_forcing)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0menc_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mteacher_forcing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-473f3b3c81d0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, enc_o, enc_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnhid_tran\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# Scaling logits. Do not modify this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'logits' referenced before assignment"]}]},{"cell_type":"code","metadata":{"id":"iXEhb6xbO850"},"source":[],"execution_count":null,"outputs":[]}]}