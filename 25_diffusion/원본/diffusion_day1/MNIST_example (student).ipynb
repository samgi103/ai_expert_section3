{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN/Z6HiHXAAxfbn5IQMNMUf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xFLZsBSGJEPq"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","source":["!pip3 install torch torchvision"],"metadata":{"id":"XfiWEjgqJO9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from typing import Dict, Tuple\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import models, transforms\n","from torchvision.datasets import MNIST\n","from torchvision.utils import save_image, make_grid\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation, PillowWriter\n","import numpy as np"],"metadata":{"id":"zie4BIg8Jhxu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### Data Setting\n","\n","batch_size = 512                 # the number of data in each iteration\n","\n","# optionally load a model\n","tf = transforms.Compose([transforms.ToTensor()]) # mnist is already normalised 0 to 1\n","\n","dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=5)"],"metadata":{"id":"MIs6TlGf2Kcm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_batch = next(iter(dataloader))[0][:100]\n","\n","plt.imshow(make_grid(sample_batch, nrow=10).permute(1, 2, 0), cmap='gray')\n","plt.show()\n","plt.close()"],"metadata":{"id":"tQOMgQ4V2PVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def beta_schedule(beta1, beta2, T, schedule='sigmoid'):\n","    if schedule == 'linear':\n","        betas = torch.linspace(beta1, beta2, T)\n","    elif schedule == \"quad\":\n","        betas = torch.linspace(beta1 ** 0.5, beta2 ** 0.5, T) ** 2\n","    elif schedule == \"sigmoid\":\n","        betas = torch.linspace(-6, 6, T)\n","        betas = torch.sigmoid(betas) * (beta2 - beta1) + beta1\n","    return betas\n","\n","def ddpm_schedules(beta1, beta2, T, schedule='sigmoid'):\n","    \"\"\"\n","    Returns pre-computed schedules for DDPM sampling, training process.\n","    \"\"\"\n","    assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n","\n","    beta_t = beta_schedule(beta1, beta2, T, schedule)\n","    # beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n","    sqrt_beta_t = torch.sqrt(beta_t)\n","    alpha_t = 1 - beta_t\n","    log_alpha_t = torch.log(alpha_t)\n","    alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n","\n","    sqrtab = torch.sqrt(alphabar_t)\n","    oneover_sqrta = 1 / torch.sqrt(alpha_t)\n","\n","    sqrtmab = torch.sqrt(1 - alphabar_t)\n","    mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n","\n","    return {\n","        \"beta_t\": beta_t,    # \\beta_t\n","        \"alpha_t\": alpha_t,  # \\alpha_t\n","        \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n","        \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n","        \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n","        \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n","        \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n","        \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n","    }\n","\n"],"metadata":{"id":"otEADZ-8KkcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ddpm scheduling check\n","\n","import matplotlib.pyplot as plt\n","\n","n_T = 400\n","\n","ddpm_scheduling_dict = ddpm_schedules(1e-4, 0.02, n_T)\n","\n","beta = ddpm_scheduling_dict['beta_t']\n","alpha = ddpm_scheduling_dict['alpha_t']\n","alpha_bar = ddpm_scheduling_dict['alphabar_t']\n","\n","fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20,6))\n","\n","axes[0].plot(np.arange(len(beta)), beta)\n","axes[0].set_xlabel('timesteps')\n","axes[0].set_ylabel('beta')\n","\n","axes[1].plot(np.arange(len(alpha)), alpha)\n","axes[1].set_xlabel('timesteps')\n","axes[1].set_ylabel('alpha')\n","\n","axes[2].plot(np.arange(len(alpha_bar)), alpha_bar)\n","axes[2].set_xlabel('timesteps')\n","axes[2].set_ylabel('alpha_bar')\n","\n","plt.show()\n","plt.close()"],"metadata":{"id":"Gk_5rm4poQee"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_batch = next(iter(dataloader))[0][:10]\n","\n","forward_list = []\n","forward_list2 = []\n","\n","x = sample_batch\n","for t in range(n_T):\n","    x = # ToDo: Write the function of x by using the forward process distribution\n","    if t % (n_T//10) == 0:\n","        forward_list.append(x.detach().cpu())\n","\n","for t in range(400):\n","    if t % (n_T//10) == 0:\n","        x = # ToDo: Write the function of sample_batch by using the reparameterization trick\n","        forward_list2.append(x.detach().cpu())\n","\n","plt.imshow(make_grid(torch.cat(forward_list), nrow=10).permute(1, 2, 0), cmap='gray')\n","plt.show()\n","plt.close()\n","\n","plt.imshow(make_grid(torch.cat(forward_list2), nrow=10).permute(1, 2, 0), cmap='gray')\n","plt.show()\n","plt.close()"],"metadata":{"id":"h9k8xnx-szY9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ResidualConvBlock(nn.Module):\n","    def __init__(\n","        self, in_channels: int, out_channels: int, is_res: bool = False\n","    ) -> None:\n","        super().__init__()\n","        '''\n","        standard ResNet style convolutional block\n","        '''\n","        self.same_channels = in_channels==out_channels\n","        self.is_res = is_res\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.GELU(),\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.GELU(),\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        if self.is_res:\n","            x1 = self.conv1(x)\n","            x2 = self.conv2(x1)\n","            # this adds on correct residual in case channels have increased\n","            if self.same_channels:\n","                out = x + x2\n","            else:\n","                out = x1 + x2\n","            return out / 1.414\n","        else:\n","            x1 = self.conv1(x)\n","            x2 = self.conv2(x1)\n","            return x2\n","\n","\n","class UnetDown(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UnetDown, self).__init__()\n","        '''\n","        process and downscale the image feature maps\n","        '''\n","        layers = [ResidualConvBlock(in_channels, out_channels), nn.MaxPool2d(2)]\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","class UnetUp(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UnetUp, self).__init__()\n","        '''\n","        process and upscale the image feature maps\n","        '''\n","        layers = [\n","            nn.ConvTranspose2d(in_channels, out_channels, 2, 2),\n","            ResidualConvBlock(out_channels, out_channels),\n","            ResidualConvBlock(out_channels, out_channels),\n","        ]\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x, skip):\n","        x = torch.cat((x, skip), 1)\n","        x = self.model(x)\n","        return x\n","\n","\n","class EmbedFC(nn.Module):\n","    def __init__(self, input_dim, emb_dim):\n","        super(EmbedFC, self).__init__()\n","        '''\n","        generic one layer FC NN for embedding things\n","        '''\n","        self.input_dim = input_dim\n","        layers = [\n","            nn.Linear(input_dim, emb_dim),\n","            nn.GELU(),\n","            nn.Linear(emb_dim, emb_dim),\n","        ]\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = x.view(-1, self.input_dim)\n","        return self.model(x)\n","\n","\n","class ContextUnet(nn.Module):\n","    def __init__(self, in_channels, n_feat = 256, n_classes=10):\n","        super(ContextUnet, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.n_feat = n_feat\n","        self.n_classes = n_classes\n","\n","        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=True)\n","\n","        self.down1 = UnetDown(n_feat, n_feat)\n","        self.down2 = UnetDown(n_feat, 2 * n_feat)\n","\n","        self.to_vec = nn.Sequential(nn.AvgPool2d(7), nn.GELU())\n","\n","        self.timeembed1 = EmbedFC(1, 2*n_feat)\n","        self.timeembed2 = EmbedFC(1, 1*n_feat)\n","        self.contextembed1 = EmbedFC(n_classes, 2*n_feat)\n","        self.contextembed2 = EmbedFC(n_classes, 1*n_feat)\n","\n","        self.up0 = nn.Sequential(\n","            # nn.ConvTranspose2d(6 * n_feat, 2 * n_feat, 7, 7), # when concat temb and cemb end up w 6*n_feat\n","            nn.ConvTranspose2d(2 * n_feat, 2 * n_feat, 7, 7), # otherwise just have 2*n_feat\n","            nn.GroupNorm(8, 2 * n_feat),\n","            nn.ReLU(),\n","        )\n","\n","        self.up1 = UnetUp(4 * n_feat, n_feat)\n","        self.up2 = UnetUp(2 * n_feat, n_feat)\n","        self.out = nn.Sequential(\n","            nn.Conv2d(2 * n_feat, n_feat, 3, 1, 1),\n","            nn.GroupNorm(8, n_feat),\n","            nn.ReLU(),\n","            nn.Conv2d(n_feat, self.in_channels, 3, 1, 1),\n","        )\n","\n","    def forward(self, x, c, t):\n","        # x is (noisy) image, c is context label, t is timestep,\n","        # context_mask says which samples to block the context on\n","\n","        x = self.init_conv(x)\n","        down1 = self.down1(x)\n","        down2 = self.down2(down1)\n","        hiddenvec = self.to_vec(down2)\n","\n","        # convert context to one hot embedding\n","        c = nn.functional.one_hot(c, num_classes=self.n_classes).type(torch.float)\n","\n","        # embed context, time step\n","        cemb1 = self.contextembed1(c).view(-1, self.n_feat * 2, 1, 1)\n","        temb1 = self.timeembed1(t).view(-1, self.n_feat * 2, 1, 1)\n","        cemb2 = self.contextembed2(c).view(-1, self.n_feat, 1, 1)\n","        temb2 = self.timeembed2(t).view(-1, self.n_feat, 1, 1)\n","\n","        # could concatenate the context embedding here instead of adaGN\n","        # hiddenvec = torch.cat((hiddenvec, temb1, cemb1), 1)\n","\n","        up1 = self.up0(hiddenvec)\n","        # up2 = self.up1(up1, down2) # if want to avoid add and multiply embeddings\n","        up2 = self.up1(cemb1*up1+ temb1, down2)  # add and multiply embeddings\n","        up3 = self.up2(cemb2*up2+ temb2, down1)\n","        out = self.out(torch.cat((up3, x), 1))\n","        return out"],"metadata":{"id":"iQAZy3k0KZpW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DDPM(nn.Module):\n","    def __init__(self, nn_model, betas, n_T, device):\n","        super(DDPM, self).__init__()\n","        self.nn_model = nn_model.to(device)\n","\n","        # register_buffer allows accessing dictionary produced by ddpm_schedules\n","        # e.g. can access self.sqrtab later\n","        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n","            self.register_buffer(k, v)\n","\n","        self.n_T = n_T\n","        self.device = device\n","        self.loss_mse = nn.MSELoss()\n","\n","    def forward(self, x, c):\n","        \"\"\"\n","        this method is used in training, so samples t and noise randomly\n","        \"\"\"\n","\n","        _ts = torch.randint(0, self.n_T, (x.shape[0],)).to(self.device)  # t ~ Uniform(0, n_T)\n","        noise = torch.randn_like(x)  # eps ~ N(0, 1)\n","\n","        x_t = (\n","            self.sqrtab[_ts, None, None, None] * x\n","            + self.sqrtmab[_ts, None, None, None] * noise\n","        )  # This is the x_t, which is sqrt(alphabar) x_0 + sqrt(1-alphabar) * eps\n","        # We should predict the \"error term\" from this x_t. Loss is what we return.\n","\n","        # return MSE between added noise, and our predicted noise\n","        eps = self.nn_model(x_t, c, _ts / self.n_T)\n","        return self.loss_mse() # ToDo: Write the loss function to train the network\n","\n","    def sample(self, n_sample, size, device):\n","        # we follow the guidance sampling scheme described in 'Classifier-Free Diffusion Guidance'\n","        # to make the fwd passes efficient, we concat two versions of the dataset,\n","        # one with context_mask=0 and the other context_mask=1\n","        # we then mix the outputs with the guidance scale, w\n","        # where w>0 means more guidance\n","\n","        x_i = torch.randn(n_sample, *size).to(device)  # x_T ~ N(0, 1), sample initial noise\n","        c_i = torch.arange(0,10).to(device) # context for us just cycles throught the mnist labels\n","        c_i = c_i.repeat(int(n_sample/c_i.shape[0]))\n","\n","        x_i_store = [] # keep track of generated steps in case want to plot something\n","        for i in range(self.n_T-1, -1, -1):\n","            print(f'sampling timestep {i}',end='\\r')\n","            t_is = torch.tensor([i / self.n_T]).to(device)\n","            t_is = t_is.repeat(n_sample,1,1,1)\n","\n","            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n","\n","            # split predictions and compute weighting\n","            eps = self.nn_model(x_i, c_i, t_is)\n","            x_i = (\n","                self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i])\n","                + self.sqrt_beta_t[i] * z\n","            )\n","            if i%20==0 or i==self.n_T or i<8:\n","                x_i_store.append(x_i.detach().cpu().numpy())\n","\n","        x_i_store = np.array(x_i_store)\n","        return x_i, x_i_store"],"metadata":{"id":"zldse5EOL8K9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device='cuda:0'\n","n_epoch = 20                     # total training epoch\n","n_T = 400                        # total timesteps of diffusion process\n","n_classes = 10                   # the number of class in dataset\n","n_feat = 128                     # feature dimension of UNet : 128 ok, 256 better (but slower)\n","lrate = 1e-4                     # learning rate\n","save_dir = './mnist_data_results/'\n","os.makedirs(save_dir, exist_ok=True)\n","\n","ddpm = DDPM(nn_model=ContextUnet(in_channels=1, n_feat=n_feat, n_classes=n_classes), betas=(1e-4, 0.02), n_T=n_T, device=device)\n","ddpm.to(device)\n","\n","optim = torch.optim.Adam(ddpm.parameters(), lr=lrate)"],"metadata":{"id":"FZBCKV9aMuDg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.ioff()\n","\n","# Training\n","for ep in range(n_epoch):\n","    print(f'epoch {ep}')\n","    ddpm.train()\n","\n","    # linear lrate decay\n","    optim.param_groups[0]['lr'] = lrate*(1-ep/n_epoch)\n","\n","    pbar = tqdm(dataloader)\n","    loss_ema = None\n","    for x, c in pbar:\n","        optim.zero_grad()\n","        x = x.to(device)\n","        c = c.to(device)\n","        loss = ddpm(x, c)\n","        loss.backward()\n","        if loss_ema is None:\n","            loss_ema = loss.item()\n","        else:\n","            loss_ema = 0.95 * loss_ema + 0.05 * loss.item()\n","        pbar.set_description(f\"loss: {loss_ema:.4f}\")\n","        optim.step()\n","\n","    # for eval, save an image of currently generated samples (top rows)\n","    # followed by real images (bottom rows)\n","    ddpm.eval()\n","    with torch.no_grad():\n","        n_sample = 4*n_classes\n","        x_gen, x_gen_store = ddpm.sample(n_sample, (1, 28, 28), device)\n","\n","        # append some real images at bottom, order by class also\n","        x_real = torch.Tensor(x_gen.shape).to(device)\n","        for k in range(n_classes):\n","            for j in range(int(n_sample/n_classes)):\n","                try:\n","                    idx = torch.squeeze((c == k).nonzero())[j]\n","                except:\n","                    idx = 0\n","                x_real[k+(j*n_classes)] = x[idx]\n","\n","        x_all = torch.cat([x_gen, x_real])\n","        grid = make_grid(x_all, nrow=10)\n","        save_image(grid, save_dir + f\"image_ep{ep}.png\")\n","        print('saved image at ' + save_dir + f\"image_ep{ep}.png\")\n","\n","        if ep%5==0 or ep == int(n_epoch-1):\n","            # create gif of images evolving over time, based on x_gen_store\n","            fig, axs = plt.subplots(nrows=int(n_sample/n_classes), ncols=n_classes,sharex=True,sharey=True,figsize=(8,3))\n","            def animate_diff(i, x_gen_store):\n","                print(f'gif animating frame {i} of {x_gen_store.shape[0]}', end='\\r')\n","                plots = []\n","                for row in range(int(n_sample/n_classes)):\n","                    for col in range(n_classes):\n","                        axs[row, col].clear()\n","                        axs[row, col].set_xticks([])\n","                        axs[row, col].set_yticks([])\n","                        # plots.append(axs[row, col].imshow(x_gen_store[i,(row*n_classes)+col,0],cmap='gray'))\n","                        plots.append(axs[row, col].imshow(x_gen_store[i,(row*n_classes)+col,0],cmap='gray',vmin=(x_gen_store[i]).min(), vmax=(x_gen_store[i]).max()))\n","                return plots\n","            ani = FuncAnimation(fig, animate_diff, fargs=[x_gen_store],  interval=200, blit=False, repeat=True, frames=x_gen_store.shape[0])\n","            ani.save(save_dir + f\"gif_ep{ep}.gif\", dpi=100, writer=PillowWriter(fps=5))\n","            print('saved image at ' + save_dir + f\"gif_ep{ep}.gif\")\n","            plt.close('all')\n","\n","    # optionally save model\n","    if ep == int(n_epoch-1):\n","        torch.save(ddpm.state_dict(), save_dir + f\"model_{ep}.pth\")\n","        print('saved model at ' + save_dir + f\"model_{ep}.pth\")"],"metadata":{"id":"TWu8xqcRKoD_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_samples = 100\n","\n","x = torch.randn((num_samples, 1, 28, 28), device=device) # xT ~ N(0, I)\n","c_i = torch.arange(0,10).to(device) # context for us just cycles throught the mnist labels\n","c_i = c_i.repeat(int(num_samples/c_i.shape[0]))\n","x_store = []\n","with torch.no_grad():\n","    for i in range(n_T-1, -1, -1):\n","        t_is = torch.tensor([i / n_T]).to(device)\n","        t_is = t_is.repeat(num_samples, 1, 1, 1)\n","\n","        eps = ddpm.nn_model(x, c_i, t_is)\n","        x = # ToDo: Write the function of x by using the backward process distribution\n","        if i % 20 == 0 or i == n_T or i < 8:\n","            x_store.append(x.detach().cpu().numpy())\n","\n","\n","plt.imshow(make_grid(x.cpu(), nrow=10).permute(1, 2, 0), cmap='gray')\n","plt.show()\n","plt.close()"],"metadata":{"id":"OiklP0267scf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7yANe2u47skG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xkdPVwk852PW"},"execution_count":null,"outputs":[]}]}