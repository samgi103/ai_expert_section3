{"cells":[{"cell_type":"markdown","source":["AI Expert - Learning with Noisy Labels Basic Practice\n","====\n","진행 조교 : 김재윤, 김우재, 조윤기\n","\n","## Instruction\n","> 안녕하세요. 본 실습 강의에서는 Learning with noisy labels와 관련된 기본적인 요소들을 직접 구현하며, 기계 학습에서 흔히 발생하는 문제 중 하나인 노이즈가 있는 데이터에 대처하는 방법에 대해 이해하는 것을 목표로 합니다. 노이즈가 있는 레이블을 다루고 해결하기 위한 간단한 기법들을 습득할 수 있습니다.\n","## Preparation\n","> 우선 창 왼쪽 상단의 **파일** 탭의, **Drive에 사본 저장** 버튼을 눌러 본 Colab 파일의 사본을 만들고, 실습을 진행하시길 바랍니다.\n","## Reference materials\n","> 아래는 본 과제 실습에서 주로 활용하는 PyTorch, NumPy 의 documentation 입니다.\n","* PyTorch \\[[Documentation](https://pytorch.org/docs/stable/index.html)\\]\n","* NumPy  \\[[Documentation](https://numpy.org/doc/stable/)\\]\n","\n","\n","\n"],"metadata":{"id":"JjSY1fMFCDWI"}},{"cell_type":"markdown","source":["## Step 1: Set the enviroments\n","실습 진행을 위한 기본적인 환경 설정을 진행합니다."],"metadata":{"id":"PqkcbONRLbKP"}},{"cell_type":"markdown","source":["### Step 1-1: Import the necessary libraries\n","Noisy label을 통한 모델 학습에 활용할 라이브러리를 import합니다."],"metadata":{"id":"zf1nSXSWLb43"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rxEXnI4M_uct"},"outputs":[],"source":["import csv\n","import os\n","import os.path\n","import pickle\n","from typing import Any, Callable, Optional, Tuple\n","import random\n","\n","import numpy as np\n","from PIL import Image\n","from tqdm.notebook import tqdm\n","\n","import torch\n","from torch.autograd import Variable\n","from torch.backends import cudnn\n","import torch.backends.cudnn as cudnn\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchvision.datasets.utils import check_integrity, download_and_extract_archive\n","from torchvision.datasets.vision import VisionDataset\n","\n","\n","random.seed(1)\n","np.random.seed(1)\n","torch.manual_seed(1)\n","torch.cuda.manual_seed(1)\n","torch.cuda.manual_seed_all(1)\n","cudnn.deterministic = True\n","cudnn.benchmark = False\n","\n","device = torch.device('cuda')"]},{"cell_type":"markdown","source":["### Step 1-2 Construct the dataset with noisy labels\n","실습에 활용할 레이블 노이즈 데이터 셋을 구성합니다. 본 실습에서는 대표적인 이미지 데이터셋인 CIFAR-10을 활용합니다. 제한된 시간에서 효율적인 실습 진행을 위해 해당 데이터셋의 일부만을 활용할 예정입니다."],"metadata":{"id":"gjSmCs1dQrcU"}},{"cell_type":"code","source":["class CIFAR10(VisionDataset):\n","    \"\"\"Modified from `CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n","\n","    Args:\n","        root (string): Root directory of dataset where directory\n","            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n","        train (bool, optional): If True, creates dataset from training set, otherwise\n","            creates from test set.\n","        transform (callable, optional): A function/transform that takes in an PIL image\n","            and returns a transformed version. E.g, ``transforms.RandomCrop``\n","        target_transform (callable, optional): A function/transform that takes in the\n","            target and transforms it.\n","        download (bool, optional): If true, downloads the dataset from the internet and\n","            puts it in root directory. If dataset is already downloaded, it is not\n","            downloaded again.\n","\n","    \"\"\"\n","\n","    base_folder = \"cifar-10-batches-py\"\n","    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n","    filename = \"cifar-10-python.tar.gz\"\n","    tgz_md5 = \"c58f30108f718f92721af3b95e74349a\"\n","    train_list = [\n","        [\"data_batch_1\", \"c99cafc152244af753f735de768cd75f\"],\n","        [\"data_batch_2\", \"d4bba439e000b95fd0a9bffe97cbabec\"],\n","        [\"data_batch_3\", \"54ebc095f3ab1f0389bbae665268c751\"],\n","        [\"data_batch_4\", \"634d18415352ddfa80567beed471001a\"],\n","        [\"data_batch_5\", \"482c414d41f54cd18b22e5b47cb7c3cb\"],\n","    ]\n","\n","    test_list = [\n","        [\"test_batch\", \"40351d587109b95175f43aff81a1287e\"],\n","    ]\n","    meta = {\n","        \"filename\": \"batches.meta\",\n","        \"key\": \"label_names\",\n","        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n","    }\n","\n","    def __init__(\n","        self,\n","        root: str,\n","        train: bool = True,\n","        transform: Optional[Callable] = None,\n","        target_transform: Optional[Callable] = None,\n","        download: bool = False,\n","        num_images_per_class: int = 1000\n","    ) -> None:\n","\n","        super().__init__(root, transform=transform, target_transform=target_transform)\n","\n","        self.train = train  # training set or test set\n","\n","        if download:\n","            self.download()\n","\n","        if not self._check_integrity():\n","            raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n","\n","        if self.train:\n","            downloaded_list = self.train_list\n","        else:\n","            downloaded_list = self.test_list\n","\n","        self.data: Any = []\n","        self.targets = []\n","\n","        # now load the picked numpy arrays\n","        for file_name, checksum in downloaded_list:\n","            file_path = os.path.join(self.root, self.base_folder, file_name)\n","            with open(file_path, \"rb\") as f:\n","                entry = pickle.load(f, encoding=\"latin1\")\n","                self.data.append(entry[\"data\"])\n","                if \"labels\" in entry:\n","                    self.targets.extend(entry[\"labels\"])\n","                else:\n","                    self.targets.extend(entry[\"fine_labels\"])\n","\n","        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n","        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n","\n","        self._load_meta()\n","\n","        ''' Truncate number of images per class to 1000 '''\n","        if num_images_per_class > 0:\n","          self.trun_data = []\n","          self.trun_targets = []\n","          count_dict = {}\n","          for data, target in zip(self.data, self.targets):\n","              if target not in count_dict:\n","                  count_dict[target] = 0\n","              if count_dict[target] >= num_images_per_class:\n","                  continue\n","              count_dict[target] += 1\n","              self.trun_data.append(data)\n","              self.trun_targets.append(target)\n","          self.data, self.targets = self.trun_data, self.trun_targets\n","\n","\n","    def _load_meta(self) -> None:\n","        path = os.path.join(self.root, self.base_folder, self.meta[\"filename\"])\n","        if not check_integrity(path, self.meta[\"md5\"]):\n","            raise RuntimeError(\"Dataset metadata file not found or corrupted. You can use download=True to download it\")\n","        with open(path, \"rb\") as infile:\n","            data = pickle.load(infile, encoding=\"latin1\")\n","            self.classes = data[self.meta[\"key\"]]\n","        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n","\n","    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n","        \"\"\"\n","        Args:\n","            index (int): Index\n","\n","        Returns:\n","            tuple: (image, target) where target is index of the target class.\n","        \"\"\"\n","        img, target = self.data[index], self.targets[index]\n","\n","        # doing this so that it is consistent with all other datasets\n","        # to return a PIL Image\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","\n","        return img, target\n","\n","    def __len__(self) -> int:\n","        return len(self.data)\n","\n","    def _check_integrity(self) -> bool:\n","        for filename, md5 in self.train_list + self.test_list:\n","            fpath = os.path.join(self.root, self.base_folder, filename)\n","            if not check_integrity(fpath, md5):\n","                return False\n","        return True\n","\n","    def download(self) -> None:\n","        if self._check_integrity():\n","            print(\"Files already downloaded and verified\")\n","            return\n","        download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n","\n","    def extra_repr(self) -> str:\n","        split = \"Train\" if self.train is True else \"Test\"\n","        return f\"Split: {split}\""],"metadata":{"id":"kydjz1BEUKwK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["아래는 구축한 CIFAR-10 데이터셋에 대하여 이미지 전처리를 적용하고 noisy label이 없는 데이터셋을 불러오는 과정입니다."],"metadata":{"id":"jHVOSKiOZ13v"}},{"cell_type":"code","source":["batch_size = 128\n","eval_batch_size = 100\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465),\n","                          (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","train_dataset = CIFAR10(root='~/data', train=True, download=True, transform=transform_train, num_images_per_class=2000)\n","testset = CIFAR10(root='~/data', train=False, download=True, transform=transform_test, num_images_per_class=-1)"],"metadata":{"id":"BSOHtRDJU_lK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[ *Problem-1* ]** Implement noisy labels. Noise 비율\\(noise_ratio\\)에 해당되는 데이터에 **random label**을 부여합니다."],"metadata":{"id":"rLj1dCLnbKnm"}},{"cell_type":"code","source":["def inject_label_noise(dataset, noise_ratio=0.5):\n","  \"\"\"\n","    Inject label noises to a given dataset\n","\n","    Args:\n","        dataset (torch.utils.data.Dataset): dataset to add noise to.\n","        noise_ratio (float): ratio to add noise . Default, 0.5\n","  \"\"\"\n","  noisy_labels = dataset.targets.copy()\n","\n","  \"\"\"\n","    Q. Write your code to inject label noises.\n","    Randomly assign labels to certain data.\n","    Using python random library and numpy.random would be helpful.\n","  \"\"\"\n","\n","  dataset.targets = noisy_labels\n","  return dataset"],"metadata":{"id":"0oHe_VuXVoq6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["아래는 구현된 inject_label_noise 함수를 활용하여 dataset에 noisy label을 추가하고, 이를 기반으로 dataset loader를 로드하는 과정입니다."],"metadata":{"id":"aeYJlpiTb6tu"}},{"cell_type":"code","source":["noisy_train_dataset = inject_label_noise(train_dataset, noise_ratio=0.5)\n","\n","train_dataloader = torch.utils.data.DataLoader(noisy_train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = torch.utils.data.DataLoader(testset, batch_size=eval_batch_size, shuffle=False)"],"metadata":{"id":"HWQlZrAuYvHF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 2: Train a image classification model with noisy labels\n","Learning with noisy labels를 위한 여러 loss 함수를 구현하고, 모델을 학습합니다."],"metadata":{"id":"I45gmlv-cf9O"}},{"cell_type":"markdown","source":["### Step 2-1: Create a image classification model\n","본 실습에서는 resnet18을 활용하여 간단한 이미지 분류 모델을 생성합니다."],"metadata":{"id":"V6FsScR5dN7c"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5693BmHL8yoV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion *\n","                               planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.classifier = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])\n","\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3, 4, 6, 3])\n","\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3, 4, 6, 3])\n","\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3, 4, 23, 3])\n","\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3, 8, 36, 3])"]},{"cell_type":"markdown","source":["아래는 입력된 loss function \\(criterion\\) 활용해 모델을 학습하는 클래스입니다."],"metadata":{"id":"-8rcFsADd6rI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPN-adgr9o2B"},"outputs":[],"source":["class Trainer(object):\n","    def __init__(self, model, device, criterion):\n","        super(Trainer, self).__init__()\n","        self.model = model\n","        self.device = device\n","        self.criterion = criterion\n","\n","    def train(self, train_dataloader, optimizer, epoch):\n","        self.model.train()\n","\n","        for i in range(epoch):\n","            for j, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc='Epoch [{} / {}]'.format(i+1,epoch)):\n","                inputs, targets = data\n","                inputs, targets = inputs.to(self.device), targets.to(self.device)\n","                outputs = self.model(inputs)\n","                loss = self.criterion(outputs, targets)  # compute cross-entropy loss\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()"]},{"cell_type":"markdown","source":["아래는 학습된 모델을 평가하는 클래스입니다."],"metadata":{"id":"a-6Dvhj3s6xV"}},{"cell_type":"code","source":["class Evaluator(object):\n","    def __init__(self, model, device):\n","        super(Evaluator, self).__init__()\n","        self.model = model\n","        self.device = device\n","\n","    def test(self, test_dataloader):\n","        self.model.eval()\n","        correct = 0\n","        total = 0\n","        for j, data in tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc='Evaluation'):\n","            inputs, targets = data\n","            inputs, targets = inputs.to(self.device), targets.to(self.device)\n","\n","            outputs = self.model(inputs)\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","        accuracy = correct/total\n","        print('\\nAccuracy: {:.2%} \\n'.format(accuracy))"],"metadata":{"id":"fLPQ61AOq5ES"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 2-2: Train a baseline model with cross-entrpy loss\n","이미지 분류 모델을 생성하고 Cross-entropy loss를 활용하여 baseline 모델을 학습합니다.\n"],"metadata":{"id":"j2w4V__ZnYNr"}},{"cell_type":"code","source":["random.seed(1)\n","np.random.seed(1)\n","torch.manual_seed(1)\n","torch.cuda.manual_seed(1)\n","torch.cuda.manual_seed_all(1)\n","\n","baseline_model = ResNet18().to(device)\n","baseline_loss = nn.CrossEntropyLoss()\n","baseline_optimizer = optim.SGD(baseline_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","baseline_trainer = Trainer(model=baseline_model, device=device, criterion=baseline_loss)\n","baseline_trainer.train(train_dataloader, baseline_optimizer, epoch=20)"],"metadata":{"id":"V6L1cVCGieoi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["baseline_evaluator = Evaluator(model=baseline_model, device=device)\n","baseline_evaluator.test(test_dataloader)"],"metadata":{"id":"AYIJxgB4rpGT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 2-3: Train a baseline model with bootstrapping loss\n","이미지 분류 모델을 생성하고 bootstrapping loss를 활용하여 모델을 학습합니다.\n"],"metadata":{"id":"eOhJkWXAnnYa"}},{"cell_type":"markdown","source":["Bootstrapping은 noisy label이 있는 환경에서 loss를 correction하는 방법 중 하나로, GT label과 model의 prediction을 혼합하여 사용하는 기법을 일컷습니다.\n","\n","강의자료에 나와 있듯이, bootstrapping은 아래 수식으로 표현될 수 있습니다:\n","\n","$\\mathcal{l}_B = (βy_i + (1-β)z_i)^T log(h_i)$.\n","\n","여기서 $y_i$ noisy한 상태로 존재할 수도 있는 GT label, 그리고 $z_i$는 모델의 prediction을 나타냅니다. $h_i$는 모델의 softmax logit output을 나타내며, $w_i$는 GT label과 logit의 가중치를 조절하는 hyperparameter를 나타냅니다.\n","\n","여기서 Soft Bootstrapping은 모델의 prediction을 그대로 사용하는 것을 의미하고, Hard Bootstrapping은 prediction score가 가장 높은 한 개의 class를 선택하여 one-hot encoding된 vector를 사용하는 것을 의미합니다. 본 실습에선 두 버전의 bootstrapping을 모두 구현하여 noisy label이 있는 환경에서의 bootstrapping 학습의 성능을 보고자 합니다."],"metadata":{"id":"KUVqGHn74saf"}},{"cell_type":"markdown","source":["**[ *Problem-2-1* ]** Implement SoftBootstrapping loss"],"metadata":{"id":"GZfdPMAUvjIg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrg1N3NTFKgx"},"outputs":[],"source":["import torch\n","from torch.nn import Module\n","import torch.nn.functional as F\n","\n","\n","class SoftBootstrappingLoss(Module):\n","    \"\"\"\n","    ``Loss(t, p) = - (beta * t + (1 - beta) * p) * log(p)``\n","\n","    Args:\n","        beta (float): bootstrap parameter. Default, 0.95\n","        reduce (bool): computes mean of the loss. Default, True.\n","        as_pseudo_label (bool): Stop gradient propagation for the term ``(1 - beta) * p``.\n","            Can be interpreted as pseudo-label.\n","    \"\"\"\n","    def __init__(self, beta=0.95, reduce=True, as_pseudo_label=True):\n","        super(SoftBootstrappingLoss, self).__init__()\n","        self.beta = beta\n","        self.reduce = reduce\n","        self.as_pseudo_label = as_pseudo_label\n","\n","    def forward(self, y_pred, y):\n","        # cross_entropy = - t * log(p)\n","        beta_xentropy = self.beta * F.cross_entropy(y_pred, y, reduction='none')\n","\n","        ''' Implement here '''\n","        bootstrap = None\n","\n","        return beta_xentropy + bootstrap\n"]},{"cell_type":"code","source":["random.seed(1)\n","np.random.seed(1)\n","torch.manual_seed(1)\n","torch.cuda.manual_seed(1)\n","torch.cuda.manual_seed_all(1)\n","\n","soft_boostrapping_model = ResNet18().to(device)\n","soft_boostrapping_loss = SoftBootstrappingLoss()\n","soft_boostrapping_optimizer = optim.SGD(soft_boostrapping_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","soft_boostrapping_trainer = Trainer(model=soft_boostrapping_model, device=device, criterion=soft_boostrapping_loss)\n","soft_boostrapping_trainer.train(train_dataloader, soft_boostrapping_optimizer, epoch=20)"],"metadata":{"id":"lD_d2P28mwZK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soft_boostrapping_evaluator = Evaluator(model=soft_boostrapping_model, device=device)\n","soft_boostrapping_evaluator.test(test_dataloader)"],"metadata":{"id":"1AU0Ct00r-0p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**[ *Problem-2-2* ]** Implement HardBootstrapping loss"],"metadata":{"id":"WCzrmn2K_1kE"}},{"cell_type":"code","source":["class HardBootstrappingLoss(Module):\n","    \"\"\"\n","    ``Loss(t, p) = - (beta * t + (1 - beta) * z) * log(p)``\n","    where ``z = argmax(p)``\n","\n","    Args:\n","        beta (float): bootstrap parameter. Default, 0.95\n","        reduce (bool): computes mean of the loss. Default, True.\n","\n","    \"\"\"\n","    def __init__(self, beta=0.8, reduce=True):\n","        super(HardBootstrappingLoss, self).__init__()\n","        self.beta = beta\n","        self.reduce = reduce\n","\n","    def forward(self, y_pred, y):\n","        # cross_entropy = - t * log(p)\n","        beta_xentropy = self.beta * F.cross_entropy(y_pred, y, reduction='none')\n","\n","        ''' Implement here '''\n","        bootstrap = None\n","\n","        return beta_xentropy + bootstrap"],"metadata":{"id":"N3Y8dQg4ms9u"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHp6ualIFt31"},"outputs":[],"source":["random.seed(1)\n","np.random.seed(1)\n","torch.manual_seed(1)\n","torch.cuda.manual_seed(1)\n","torch.cuda.manual_seed_all(1)\n","\n","hard_boostrapping_model = ResNet18().to(device)\n","hard_boostrapping_loss = HardBootstrappingLoss()\n","hard_boostrapping_optimizer = optim.SGD(hard_boostrapping_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","hard_boostrapping_trainer = Trainer(model=hard_boostrapping_model, device=device, criterion=hard_boostrapping_loss)\n","hard_boostrapping_trainer.train(train_dataloader, hard_boostrapping_optimizer, epoch=20)"]},{"cell_type":"code","source":["hard_boostrapping_evaluator = Evaluator(model=hard_boostrapping_model, device=device)\n","hard_boostrapping_evaluator.test(test_dataloader)"],"metadata":{"id":"oQvK6AEzsAdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 2-3: Train a baseline model with mixup\n","이미지 분류 모델을 생성하고 mixup을 활용하여 모델을 학습합니다.\n"],"metadata":{"id":"exuCymK7nxoa"}},{"cell_type":"markdown","source":["강의 자료와 같이, 아래 수식은 각각 input과 loss에 대한 mixup 형태의 data augmentation 수식입니다.\n","<div align=\"center\">\n","$x = \\delta x_a + (1 - \\delta) x_b$\n","\n","$\\ell = \\delta \\ell_a + (1 - \\delta) \\ell_b$\n","</div>\n","\n","아래 그림은 위 input 수식에서 두개의 이미지를 weighted alpha blending하는 예시입니다다.\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?export=view&id=1f3FXcUujGppFyqFC6NvL8SyZX7JTYx2o\" width=\"400\"/>\n","</div>\n","\n","여기서 $\\delta$는 mixup parameter로, 학습 iteration마다 랜덤하게 추출되어 활용됩니다. $\\delta$의 추출에 주로 활용되는 확률 분포 함수는 beta distribution이며, 이를 구현하여 사용합니다.본 실습에서는 mixup parameter인 위 $\\delta$를 학습 iteration마다 랜덤하게 추출하여 활용합니다. 아래 그림은 beta distribution의 parameter별 확률 밀도 함수(PDF)를 나타냅니다.\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?export=view&id=1vTfz8b4bz1bWJLEdVw_WZfCknOI6v4oG\" width=\"400\"/>\n","</div>\n","\n","본 실습에서는 이러한 mixup 알고리즘을 구현하고, 이를 사용하여 noisy label이 있는 상황에서도 네트워크의 강건한 훈련을 성능 향상을 통해 확인합니다."],"metadata":{"id":"HvYupogBmcy0"}},{"cell_type":"markdown","source":["**[ *Problem-3* ]** Implement training with mixup"],"metadata":{"id":"S4rjMkFq__Ok"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mu2wv4CRFIhv"},"outputs":[],"source":["def mixup_data(x, y, alpha=0.2):\n","    '''Returns mixed inputs, pairs of targets, and delta'''\n","\n","    delta = np.random.beta(alpha, alpha)\n","    \"\"\"\n","\t\tQ. Write your code to get mixed inputs, pairs of targets, and delta.\n","\t\t\"\"\"\n","\n","    return mixed_x, y_a, y_b, delta\n","\n","\n","class mixup_criterion(Module):\n","    \"\"\"\n","    Args:\n","        beta (float): bootstrap parameter. Default, 0.95\n","    \"\"\"\n","    def __init__(self, criterion):\n","        super(mixup_criterion, self).__init__()\n","        self.criterion = criterion\n","\n","    def forward(self, y_pred, y_a, y_b, delta):\n","        \t\"\"\"\n","\t\t      Q. Write your code to compute mixup-loss.\n","\t\t      \"\"\"\n","\n","        return loss\n"]},{"cell_type":"code","source":["class MixupTrainer(object):\n","    def __init__(self, model, device, criterion=mixup_criterion(criterion=nn.CrossEntropyLoss())):\n","        super(MixupTrainer, self).__init__()\n","        self.model = model\n","        self.device = device\n","        self.criterion = criterion\n","\n","    def train(self, train_dataloader, optimizer, epoch):\n","        self.model.train()\n","\n","        for i in range(epoch):\n","            for j, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc='Epoch [{} / {}]'.format(i+1,epoch)):\n","                inputs, targets = data\n","                inputs, targets = inputs.to(self.device), targets.to(self.device)\n","                inputs, targets_a, targets_b, delta = mixup_data(inputs, targets)\n","\n","                outputs = self.model(inputs)\n","                loss = self.criterion(outputs, targets_a, targets_b, delta)\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()"],"metadata":{"id":"zHjbfOjuqLDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"820ttnF3Fu8n"},"outputs":[],"source":["random.seed(1)\n","np.random.seed(1)\n","torch.manual_seed(1)\n","torch.cuda.manual_seed(1)\n","torch.cuda.manual_seed_all(1)\n","\n","mixup_model = ResNet18().to(device)\n","mixup_loss = mixup_criterion(criterion=nn.CrossEntropyLoss())\n","mixup_optimizer = optim.SGD(mixup_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","mixup_trainer = MixupTrainer(model=mixup_model, device=device, criterion=mixup_loss)\n","mixup_trainer.train(train_dataloader, mixup_optimizer, epoch=20)"]},{"cell_type":"code","source":["mixup_evaluator = Evaluator(model=mixup_model, device=device)\n","mixup_evaluator.test(test_dataloader)"],"metadata":{"id":"i2oyrs0CsINR"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1wOndAy7eSfvYxCqedMz1ptbt8ur0whrS","timestamp":1694147582579}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}