{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge distillation 실습"
      ],
      "metadata": {
        "id": "0TYlew65XRyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Don't modify! Only run!"
      ],
      "metadata": {
        "id": "rOPHBDKCXZ_y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-yTDH5BQaAs",
        "outputId": "ef67e496-7da8-4e31-f89a-602cdf252a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make directorch to save dataset\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./data')"
      ],
      "metadata": {
        "id": "EocDCiHARJ7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformation\n",
        "ds_transform = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,),(0.3081,))\n",
        "])"
      ],
      "metadata": {
        "id": "nQiLYkkoRLF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load MNIST dataset\n",
        "train_ds = datasets.MNIST('/content/data',train=True, download=True, transform=ds_transform)\n",
        "val_ds = datasets.MNIST('/content/data',train=False, download=True, transform=ds_transform)"
      ],
      "metadata": {
        "id": "Ly3gLmGMRMU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define data loader\n",
        "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size = 128, shuffle=True)"
      ],
      "metadata": {
        "id": "tXn55iRVROfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check sample image\n",
        "for x, y in train_dl:\n",
        "    print(x.shape, y.shape)\n",
        "    break\n",
        "\n",
        "num = 4\n",
        "img = x[:num]\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "for i in range(num):\n",
        "    plt.subplot(1,num+1,i+1)\n",
        "    plt.imshow(to_pil_image(0.1307*img[i]+0.3081), cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "lrXJK-vURO4r",
        "outputId": "0046c31c-3465-4500-a1cf-1750d42c84ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Teacher(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 1200)\n",
        "        self.bn1 = nn.BatchNorm1d(1200)\n",
        "        self.fc2 = nn.Linear(1200,1200)\n",
        "        self.bn2 = nn.BatchNorm1d(1200)\n",
        "        self.fc3 = nn.Linear(1200, 10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.dropout(x,p=0.8)\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = F.dropout(x,p=0.8)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "smcdVA4JRP4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check\n",
        "x = torch.randn(16,1,28,28).to(device)\n",
        "teacher = Teacher().to(device)\n",
        "output = teacher(x)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA1LtwSrRSRm",
        "outputId": "7fef9c32-b200-4271-91e8-9ac321e3b088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weight initialization\n",
        "def initialize_weights(model):\n",
        "    classname = model.__class__.__name__\n",
        "    # fc layer\n",
        "    if classname.find('Linear') != -1:\n",
        "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(model.bias.data, 0)\n",
        "    # batchnorm\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(model.bias.data, 0)\n",
        "\n",
        "teacher.apply(initialize_weights);"
      ],
      "metadata": {
        "id": "M4Tgtpt0RVkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "opt = optim.Adam(teacher.parameters())\n",
        "\n",
        "# lr scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)"
      ],
      "metadata": {
        "id": "YMqZcka1RXE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get current lr\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "# calculate the metric per mini-batch\n",
        "def metric_batch(output, target):\n",
        "    pred = output.argmax(1, keepdim=True)\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "\n",
        "# calculate the loss per mini-batch\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss_b = loss_func(output, target)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss_b.item(), metric_b\n",
        "\n",
        "\n",
        "# calculate the loss per epochs\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        output = model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        running_loss += loss_b\n",
        "\n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    loss = running_loss / len_data\n",
        "    metric = running_metric / len_data\n",
        "    return loss, metric\n",
        "\n",
        "\n",
        "# function to start training\n",
        "def train_val(model, params):\n",
        "    num_epochs=params['num_epochs']\n",
        "    loss_func=params['loss_func']\n",
        "    opt=params['optimizer']\n",
        "    train_dl=params['train_dl']\n",
        "    val_dl=params['val_dl']\n",
        "    sanity_check=params['sanity_check']\n",
        "    lr_scheduler=params['lr_scheduler']\n",
        "    path2weights=params['path2weights']\n",
        "\n",
        "    loss_history = {'train': [], 'val': []}\n",
        "    metric_history = {'train': [], 'val': []}\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "        loss_history['val'].append(val_loss)\n",
        "        metric_history['val'].append(val_metric)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), path2weights)\n",
        "            print('Copied best model weights!')\n",
        "\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            print('Loading best model weights!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "        print('-'*10)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history"
      ],
      "metadata": {
        "id": "OPAztoDlRY4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set hyper parameters\n",
        "params_train = {\n",
        "    'num_epochs':30,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_dl,\n",
        "    'val_dl':val_dl,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/teacher_weights.pt',\n",
        "}\n",
        "\n",
        "createFolder('./models')"
      ],
      "metadata": {
        "id": "DWBn2sthRaEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher, loss_hist, metric_hist = train_val(teacher, params_train)"
      ],
      "metadata": {
        "id": "-zYprlpXRbQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = params_train['num_epochs']\n",
        "\n",
        "# Plot train-val loss\n",
        "plt.title('Train-Val Loss')\n",
        "plt.plot(range(1, num_epochs+1), loss_hist['train'], label='train')\n",
        "plt.plot(range(1, num_epochs+1), loss_hist['val'], label='val')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot train-val accuracy\n",
        "plt.title('Train-Val Accuracy')\n",
        "plt.plot(range(1, num_epochs+1), metric_hist['train'], label='train')\n",
        "plt.plot(range(1, num_epochs+1), metric_hist['val'], label='val')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RbEkkXWTRcl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try it!\n"
      ],
      "metadata": {
        "id": "rjHOpA7nXnRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Design the architecutre of Student!\n",
        "아래 코드 Student는 Teacher와 같은 architecture를 가지고 있습니다.\n",
        "\n",
        "아래 코드를 수정하여, Student의 architecture 크기를 줄여보세요.\n",
        "\n",
        "* (Teacher보다 성능이 많이 떨어지지 않는 한도 내에서,) 사이즈가 최대한 줄여보세요."
      ],
      "metadata": {
        "id": "PrxI5ciqXsov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Student(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 1200)\n",
        "        self.bn1 = nn.BatchNorm1d(1200)\n",
        "        self.fc2 = nn.Linear(1200,1200)\n",
        "        self.bn2 = nn.BatchNorm1d(1200)\n",
        "        self.fc3 = nn.Linear(1200, 10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.dropout(x,p=0.8)\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = F.dropout(x,p=0.8)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4-Lniu9vRfpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check\n",
        "x = torch.randn(16,1,28,28).to(device)\n",
        "student = Student().to(device)\n",
        "output = student(x)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8Z-0vJARgus",
        "outputId": "c0b341d7-a34d-4627-9c8a-94b24bd7a827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weight initialization\n",
        "def initialize_weights(model):\n",
        "    classname = model.__class__.__name__\n",
        "    # fc layer\n",
        "    if classname.find('Linear') != -1:\n",
        "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(model.bias.data, 0)\n",
        "    # batchnorm\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(model.bias.data, 0)\n",
        "\n",
        "student.apply(initialize_weights);"
      ],
      "metadata": {
        "id": "r9H34ElhRiNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = Teacher().to(device)\n",
        "# load weight\n",
        "teacher.load_state_dict(torch.load('/content/models/teacher_weights.pt'))\n",
        "\n",
        "student = Student().to(device)\n",
        "\n",
        "# optimizer\n",
        "opt = optim.Adam(student.parameters())"
      ],
      "metadata": {
        "id": "LBghmFtiRj_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# knowledge distillation loss\n",
        "def distillation(y, labels, teacher_scores, T, alpha):\n",
        "    # distillation loss + classification loss\n",
        "    # y: student\n",
        "    # labels: hard label\n",
        "    # teacher_scores: soft label\n",
        "    return nn.KLDivLoss()(F.log_softmax(y/T), F.softmax(teacher_scores/T)) * (T*T * 2.0 + alpha) + F.cross_entropy(y,labels) * (1.-alpha)\n",
        "\n",
        "# val loss\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "c3XEPGVFRk7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distill_loss_batch(output, target, teacher_output, loss_fn=distillation, opt=opt, temperature=20.0):\n",
        "    loss_b = loss_fn(output, target, teacher_output, T=temperature, alpha=0.7)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss_b.item(), metric_b"
      ],
      "metadata": {
        "id": "gjeYj0BhRmOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis the effect of temperature\n",
        "temperature의 영향을 분석하세요.\n",
        "temperature의 변화에 따라, 학습 경향성이 달라집니다."
      ],
      "metadata": {
        "id": "f1k6an3pZa7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs= 100 # 초반 경향성만 보려면 epoch을 줄여서 사용하세요.\n",
        "temperature = 1.0 # Blank # 1.0 은 예시입니다. 바꿔서 사용하세요."
      ],
      "metadata": {
        "id": "lbUt8BLvZp_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history = {'train': [], 'val': []}\n",
        "metric_history = {'train': [], 'val': []}\n",
        "\n",
        "best_loss = float('inf')\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "    # train\n",
        "    student.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(train_dl.dataset)\n",
        "\n",
        "    for xb, yb in train_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        output = student(xb)\n",
        "        teacher_output = teacher(xb).detach()\n",
        "        loss_b, metric_b = distill_loss_batch(output, yb, teacher_output, loss_fn=distillation, opt=opt, temperature=temperature)\n",
        "        running_loss += loss_b\n",
        "        running_metric += metric_b\n",
        "    train_loss = running_loss / len_data\n",
        "    train_metric = running_metric / len_data\n",
        "\n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    # validation\n",
        "    student.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss, val_metric = loss_epoch(student, loss_func, val_dl)\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "\n",
        "    lr_scheduler.step(val_loss)\n",
        "\n",
        "    print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    print('-'*10)"
      ],
      "metadata": {
        "id": "eNJQjsLbRopz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot train-val loss\n",
        "plt.title('Train-Val Loss')\n",
        "plt.plot(range(1, num_epochs+1), loss_history['train'], label='train')\n",
        "plt.plot(range(1, num_epochs+1), loss_history['val'], label='val')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot train-val accuracy\n",
        "plt.title('Train-Val Accuracy')\n",
        "plt.plot(range(1, num_epochs+1), metric_history['train'], label='train')\n",
        "plt.plot(range(1, num_epochs+1), metric_history['val'], label='val')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GsRRV58VRpRk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}